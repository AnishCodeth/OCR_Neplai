{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:38:37.430285Z","iopub.execute_input":"2024-11-27T07:38:37.430779Z","iopub.status.idle":"2024-11-27T07:38:37.784511Z","shell.execute_reply.started":"2024-11-27T07:38:37.430738Z","shell.execute_reply":"2024-11-27T07:38:37.783830Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install gdown\n!gdown --id 180ZFUoAW3OEW_DL7bLnahd05K_61cdM3 -O dataset.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:38:13.877536Z","iopub.execute_input":"2024-11-27T07:38:13.878192Z","iopub.status.idle":"2024-11-27T07:38:34.481818Z","shell.execute_reply.started":"2024-11-27T07:38:13.878147Z","shell.execute_reply":"2024-11-27T07:38:34.481003Z"}},"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=180ZFUoAW3OEW_DL7bLnahd05K_61cdM3\nFrom (redirected): https://drive.google.com/uc?id=180ZFUoAW3OEW_DL7bLnahd05K_61cdM3&confirm=t&uuid=f97ad48b-6d26-42b7-a854-bbe63ccc4dcf\nTo: /kaggle/working/dataset.zip\n100%|████████████████████████████████████████| 430M/430M [00:05<00:00, 74.5MB/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:38:50.652662Z","iopub.execute_input":"2024-11-27T07:38:50.653469Z","iopub.status.idle":"2024-11-27T07:38:50.659765Z","shell.execute_reply.started":"2024-11-27T07:38:50.653419Z","shell.execute_reply":"2024-11-27T07:38:50.658917Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!unzip -q /kaggle/working/dataset.zip -d /kaggle/working/ ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:38:55.383655Z","iopub.execute_input":"2024-11-27T07:38:55.384475Z","iopub.status.idle":"2024-11-27T07:39:11.504696Z","shell.execute_reply.started":"2024-11-27T07:38:55.384426Z","shell.execute_reply":"2024-11-27T07:39:11.503571Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"image_dir='/kaggle/working/datasets/images'\nimage_index='/kaggle/working/datasets/map.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:39:15.723235Z","iopub.execute_input":"2024-11-27T07:39:15.723590Z","iopub.status.idle":"2024-11-27T07:39:15.728144Z","shell.execute_reply.started":"2024-11-27T07:39:15.723560Z","shell.execute_reply":"2024-11-27T07:39:15.727093Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_map=pd.read_csv(image_index,encoding='utf-8')\ndf_map.columns=['image_name','text']\nprint(df_map.shape)\ndf_map.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:39:19.747661Z","iopub.execute_input":"2024-11-27T07:39:19.748466Z","iopub.status.idle":"2024-11-27T07:39:20.169871Z","shell.execute_reply.started":"2024-11-27T07:39:19.748434Z","shell.execute_reply":"2024-11-27T07:39:20.168984Z"}},"outputs":[{"name":"stdout","text":"(214404, 2)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                   image_name             text\n0  2_0a362ed3-2d63-416b-8e81-6496fadb6969.png  उपभोक्तासरकारले\n1  3_7aae1a65-5af8-4930-b67f-eb8e26c6c1bf.png        बाध्यताले\n2  4_42ce5166-0155-408c-9f42-871b96ec7063.png               नै\n3  5_2401853b-cb9a-493f-bb25-ffaee5aad6a0.png          इन्धनको\n4  6_0e206342-82c6-4997-b378-e2fd8d838322.png            मूल्य","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_0a362ed3-2d63-416b-8e81-6496fadb6969.png</td>\n      <td>उपभोक्तासरकारले</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3_7aae1a65-5af8-4930-b67f-eb8e26c6c1bf.png</td>\n      <td>बाध्यताले</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_42ce5166-0155-408c-9f42-871b96ec7063.png</td>\n      <td>नै</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5_2401853b-cb9a-493f-bb25-ffaee5aad6a0.png</td>\n      <td>इन्धनको</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6_0e206342-82c6-4997-b378-e2fd8d838322.png</td>\n      <td>मूल्य</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"\ndf_map = df_map.dropna(subset=['text'])\ndf_map.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:39:27.802885Z","iopub.execute_input":"2024-11-27T07:39:27.803219Z","iopub.status.idle":"2024-11-27T07:39:27.840293Z","shell.execute_reply.started":"2024-11-27T07:39:27.803192Z","shell.execute_reply":"2024-11-27T07:39:27.839393Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(214403, 2)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"images_path=[os.path.join(image_dir,x) for x in os.listdir(image_dir)]\nimages_path[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:39:30.030929Z","iopub.execute_input":"2024-11-27T07:39:30.031252Z","iopub.status.idle":"2024-11-27T07:39:30.434260Z","shell.execute_reply.started":"2024-11-27T07:39:30.031225Z","shell.execute_reply":"2024-11-27T07:39:30.433583Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/datasets/images/165254_9623ffa3-521c-49cc-a167-4c974fff05e8.png'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import unicodedata\n\nchar_to_index = {}\ncount = 0\ntotal_text=''.join((df_map['text'].values))\n\nfor x in total_text:\n    # Filter only printable characters (not control or formatting characters)\n    if unicodedata.category(x)[0] != 'C' and x not in char_to_index:\n        count += 1\n        char_to_index[x] = count\n\nindex_to_char = {v: k for k, v in char_to_index.items()}\nprint(index_to_char)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:39:32.397179Z","iopub.execute_input":"2024-11-27T07:39:32.398075Z","iopub.status.idle":"2024-11-27T07:39:33.388559Z","shell.execute_reply.started":"2024-11-27T07:39:32.398037Z","shell.execute_reply":"2024-11-27T07:39:33.387722Z"}},"outputs":[{"name":"stdout","text":"{1: 'उ', 2: 'प', 3: 'भ', 4: 'ो', 5: 'क', 6: '्', 7: 'त', 8: 'ा', 9: 'स', 10: 'र', 11: 'ल', 12: 'े', 13: 'ब', 14: 'ध', 15: 'य', 16: 'न', 17: 'ै', 18: 'इ', 19: 'म', 20: 'ू', 21: 'च', 22: 'ढ', 23: 'ए', 24: 'ि', 25: 'ज', 26: 'ह', 27: 'ु', 28: 'छ', 29: 'ई', 30: 'आ', 31: 'फ', 32: 'ष', 33: 'ी', 34: 'ौ', 35: 'द', 36: 'व', 37: 'ं', 38: 'थ', 39: 'घ', 40: 'ग', 41: 'ठ', 42: '3', 43: '4', 44: '_', 45: '8', 46: '9', 47: '5', 48: 'e', 49: '1', 50: 'd', 51: '-', 52: 'a', 53: 'b', 54: '2', 55: 'c', 56: '7', 57: 'f', 58: '.', 59: 'p', 60: 'n', 61: 'g', 62: ',', 63: '0', 64: '6', 65: 'अ', 66: 'ँ', 67: 'श', 68: 'ट', 69: 'ृ', 70: 'ख', 71: 'ण', 72: 'ड', 73: 'झ', 74: 'ः', 75: 'ञ', 76: 'औ', 77: 'ओ', 78: 'ङ', 79: 'ऋ', 80: 'ऊ', 81: 'ऐ', 82: '|', 83: '\"', 84: '़', 85: 'ज़', 86: 'ॉ', 87: 'ऑ', 88: '`', 89: 'ऽ', 90: 'ॠ', 91: '▇', 92: '·', 93: 'ˆ', 94: 'ॆ', 95: 'ड़', 96: '¥', 97: '÷', 98: '~', 99: 'ॐ'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"top_characters=[12,17,37,66,94] #write indexes\nbottom_characters=[20,27,69,84,6] #bottom indexes\nothers=[24,33,34]\nmiddle_characters=[x for x in range(1,len(index_to_char)+1) if x not in top_characters and x not in bottom_characters and x not in others]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:39:42.815138Z","iopub.execute_input":"2024-11-27T07:39:42.815749Z","iopub.status.idle":"2024-11-27T07:39:42.820271Z","shell.execute_reply.started":"2024-11-27T07:39:42.815716Z","shell.execute_reply":"2024-11-27T07:39:42.819373Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import numpy as np\n\npadding_value = -1\nmax_length_of_word=28\n\ndef middle_label(x,padding_value,max_length_of_word,position_labels):\n    x=[y for y in x if y  in char_to_index]\n    x=[char_to_index[y] for y in x  if char_to_index[y]  in position_labels ]\n    return x + [padding_value] * (max_length_of_word - len(x)) if len(x) < max_length_of_word else x[:max_length_of_word]\n\n#logic is not working\ndef top_bottom_label(x,padding_value,max_length_of_word,position_labels):\n    x=[y for y in x if y  in char_to_index]\n    temp=[]\n    for y in x:\n        if char_to_index[y] in middle_characters:\n            temp.append(0)\n        elif char_to_index[y] in position_labels:\n            temp.append(char_to_index[y])\n    x=[*temp[1:],0]\n    return x + [padding_value] * (max_length_of_word - len(x)) if len(x) < max_length_of_word else x[:max_length_of_word]   \n\ndf_map['top_labels'] = df_map['text'].map(lambda x:top_bottom_label(x,padding_value,max_length_of_word,top_characters))\ndf_map['middle_labels']=df_map['text'].map(lambda x:middle_label(x,padding_value,max_length_of_word,middle_characters))\ndf_map['bottom_labels']=df_map['text'].map(lambda x:top_bottom_label(x,padding_value,max_length_of_word,bottom_characters))\n\ndf_map.tail()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:15:46.460995Z","iopub.execute_input":"2024-11-27T09:15:46.461688Z","iopub.status.idle":"2024-11-27T09:15:53.513583Z","shell.execute_reply.started":"2024-11-27T09:15:46.461648Z","shell.execute_reply":"2024-11-27T09:15:53.512600Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                             image_name             text  \\\n214399  252547_d4eced6d-fac6-44ef-bf36-3c1c2a418bc2.png  जनअसन्तुष्टिलाई   \n214400  252548_45a82477-7b15-411b-8522-29c6fade43bf.png   शक्तिविन्यासमा   \n214401  252549_2583688d-dad1-4fa4-92b1-123fb8fa0465.png         जनउभारले   \n214402  252550_8f18eed9-e332-4d05-a16d-e216cecc3cae.png           थकाउँछ   \n214403  252551_77da0a72-68b6-4db1-91d4-212fd382937b.png       परिणतिमाथि   \n\n                                               top_labels  \\\n214399  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, ...   \n214400  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1,...   \n214401  [0, 0, 0, 0, 0, 0, 12, 0, -1, -1, -1, -1, -1, ...   \n214402  [0, 0, 0, 66, 0, 0, -1, -1, -1, -1, -1, -1, -1...   \n214403  [0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, ...   \n\n                                            middle_labels  \\\n214399  [25, 16, 65, 9, 16, 7, 32, 68, 11, 8, 29, -1, ...   \n214400  [67, 5, 7, 36, 16, 15, 8, 9, 19, 8, -1, -1, -1...   \n214401  [25, 16, 1, 3, 8, 10, 11, -1, -1, -1, -1, -1, ...   \n214402  [38, 5, 8, 1, 28, -1, -1, -1, -1, -1, -1, -1, ...   \n214403  [2, 10, 71, 7, 19, 8, 38, -1, -1, -1, -1, -1, ...   \n\n                                            bottom_labels  \n214399  [0, 0, 0, 0, 6, 0, 27, 0, 6, 0, 0, 0, 0, 0, -1...  \n214400  [0, 6, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, -1, -1, -...  \n214401  [0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, ...  \n214402  [0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1...  \n214403  [0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text</th>\n      <th>top_labels</th>\n      <th>middle_labels</th>\n      <th>bottom_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>214399</th>\n      <td>252547_d4eced6d-fac6-44ef-bf36-3c1c2a418bc2.png</td>\n      <td>जनअसन्तुष्टिलाई</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, ...</td>\n      <td>[25, 16, 65, 9, 16, 7, 32, 68, 11, 8, 29, -1, ...</td>\n      <td>[0, 0, 0, 0, 6, 0, 27, 0, 6, 0, 0, 0, 0, 0, -1...</td>\n    </tr>\n    <tr>\n      <th>214400</th>\n      <td>252548_45a82477-7b15-411b-8522-29c6fade43bf.png</td>\n      <td>शक्तिविन्यासमा</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1,...</td>\n      <td>[67, 5, 7, 36, 16, 15, 8, 9, 19, 8, -1, -1, -1...</td>\n      <td>[0, 6, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, -1, -1, -...</td>\n    </tr>\n    <tr>\n      <th>214401</th>\n      <td>252549_2583688d-dad1-4fa4-92b1-123fb8fa0465.png</td>\n      <td>जनउभारले</td>\n      <td>[0, 0, 0, 0, 0, 0, 12, 0, -1, -1, -1, -1, -1, ...</td>\n      <td>[25, 16, 1, 3, 8, 10, 11, -1, -1, -1, -1, -1, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, ...</td>\n    </tr>\n    <tr>\n      <th>214402</th>\n      <td>252550_8f18eed9-e332-4d05-a16d-e216cecc3cae.png</td>\n      <td>थकाउँछ</td>\n      <td>[0, 0, 0, 66, 0, 0, -1, -1, -1, -1, -1, -1, -1...</td>\n      <td>[38, 5, 8, 1, 28, -1, -1, -1, -1, -1, -1, -1, ...</td>\n      <td>[0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1...</td>\n    </tr>\n    <tr>\n      <th>214403</th>\n      <td>252551_77da0a72-68b6-4db1-91d4-212fd382937b.png</td>\n      <td>परिणतिमाथि</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, ...</td>\n      <td>[2, 10, 71, 7, 19, 8, 38, -1, -1, -1, -1, -1, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"[x for x in df_map[\"text\"][214400]]\nprint(char_to_index['श'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:06:05.045674Z","iopub.execute_input":"2024-11-27T09:06:05.046039Z","iopub.status.idle":"2024-11-27T09:06:05.050922Z","shell.execute_reply.started":"2024-11-27T09:06:05.046007Z","shell.execute_reply":"2024-11-27T09:06:05.050047Z"}},"outputs":[{"name":"stdout","text":"67\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"len(df_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:40:12.569066Z","iopub.execute_input":"2024-11-27T07:40:12.569713Z","iopub.status.idle":"2024-11-27T07:40:12.575483Z","shell.execute_reply.started":"2024-11-27T07:40:12.569679Z","shell.execute_reply":"2024-11-27T07:40:12.574422Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"214403"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df_map.iloc[0, 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:40:14.153253Z","iopub.execute_input":"2024-11-27T07:40:14.153596Z","iopub.status.idle":"2024-11-27T07:40:14.159852Z","shell.execute_reply.started":"2024-11-27T07:40:14.153564Z","shell.execute_reply":"2024-11-27T07:40:14.158940Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'2_0a362ed3-2d63-416b-8e81-6496fadb6969.png'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom PIL import Image\nfrom torchvision import transforms\n\n\nimage_height,image_width=64,224\nclass NepaliTextImageDataset(Dataset):\n    def __init__(self, df_map, image_dir, transform=None):\n        \"\"\"\n        Custom Dataset for Nepali text and images.\n\n        Args:\n            df_map (DataFrame): DataFrame containing image paths and text labels.\n            image_dir (str): Directory containing image files.\n            transform (callable, optional): Transformations to apply to the images.\n        \"\"\"\n        self.df_map = df_map\n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df_map)\n\n    def __getitem__(self, idx):\n        # Get the image filename and text label from the CSV\n        img_name = os.path.join(self.image_dir, self.df_map.iloc[idx, 0])\n        text_label = self.df_map.iloc[idx, 1]\n        image = Image.open(img_name)\n        image_np = np.array(image)\n\n        _, image_bin = cv2.threshold(image_np, 127, 255, cv2.THRESH_BINARY)\n        image=Image.fromarray(image_bin)\n\n        if self.transform:\n            image = self.transform(image)\n        label = torch.tensor(self.df_map.iloc[idx, 2:])\n\n        return image, label\n\n\n# Define transforms for images\nimage_transforms = transforms.Compose([\n    # transforms.Resize((image_height, image_width)),  # Resize images to a fixed size\n    transforms.ToTensor(),                          # Convert to tensor\n    transforms.Normalize((0.5,), (0.5,))            # Normalize pixel values to [-1, 1]\n])\n\n# Create the full dataset\nfull_dataset = NepaliTextImageDataset(df_map=df_map, image_dir=image_dir, transform=image_transforms)\n\n# Split the dataset into train and test sets\ntrain_size = int(0.8 * len(full_dataset))  # 80% training\ntest_size = len(full_dataset) - train_size\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# Check the DataLoader\nfor images, labels in train_loader:\n    print(\"Image batch shape:\", images.shape)  # Shape: (batch_size, channels, height, width)\n    print(\"Label batch example:\", labels[0])   # Tensor of Unicode code points\n    break","metadata":{"execution":{"iopub.status.busy":"2024-11-27T09:15:56.469825Z","iopub.execute_input":"2024-11-27T09:15:56.470187Z","iopub.status.idle":"2024-11-27T09:15:56.808110Z","shell.execute_reply.started":"2024-11-27T09:15:56.470157Z","shell.execute_reply":"2024-11-27T09:15:56.807045Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n","output_type":"stream"},{"name":"stdout","text":"Image batch shape: torch.Size([64, 1, 64, 256])\nLabel batch example: tensor([[ 0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n        [ 9,  8,  9, 38,  8,  2,  5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n        [ 0,  0,  6,  0,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# to show image\nimport matplotlib.pyplot as plt\n\ndef show_image(image,title=None):\n    plt.title(title)\n    plt.imshow(image.permute(1,2,0).squeeze(),cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T07:41:35.366327Z","iopub.execute_input":"2024-11-27T07:41:35.367084Z","iopub.status.idle":"2024-11-27T07:41:35.372087Z","shell.execute_reply.started":"2024-11-27T07:41:35.367047Z","shell.execute_reply":"2024-11-27T07:41:35.371237Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"batch=next(iter(train_loader))\nimg = batch[0][0] \ntitle = batch[1][0]\nprint(img.shape)\nshow_image(img,title)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:27:04.777742Z","iopub.execute_input":"2024-11-27T09:27:04.778154Z","iopub.status.idle":"2024-11-27T09:27:05.409046Z","shell.execute_reply.started":"2024-11-27T09:27:04.778115Z","shell.execute_reply":"2024-11-27T09:27:05.407915Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([1, 64, 256])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAj4AAAEmCAYAAABiX5rHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3BklEQVR4nO3deVxUZfs/8M9hH/Z9kyVUXFFUJEVNxEw0zcql8HFBMy33PbXywUpL07JSw60HjdTHLH3cUjNFySV3xRU3UFRQBBlANmGu3x/85nwZBwSGc4bter9e83oxZ27OdZ91rjnnPvctEBGBMcYYY6weMKjuCjDGGGOM6QsnPowxxhirNzjxYYwxxli9wYkPY4wxxuoNTnwYY4wxVm9w4sMYY4yxeoMTH8YYY4zVG5z4MMYYY6ze4MSHMcYYY/UGJz7/39dff41mzZpBpVIBAA4dOgRBEMTX6dOnxbLdunUTp/ft27e6qswYY4yxSqpU4nPs2DHMmzcPGRkZMlWnemRmZmLRokWYNWsWDAw0V8nHH3+M6OhoNGzYUGN6s2bNEB0djRkzZlQoxtWrV9GrVy9YWlrC3t4ew4YNQ2pqqmTLoJafn49Zs2bB3d0dCoUCHTp0wP79+6s0zwULFqBfv35wcXGBIAiYN29eqeW2bt2Kd999Fw0bNoS5uTmaNm2K6dOny7a//PTTT2jevDnMzMzg6+uLZcuWyRKnNm+7suzYsQPt2rWDmZkZvLy8EBERgcLCQsnj3L9/H++88w5sbW1hbW2NN998E7dv35Y8Tnx8PKZOnYpOnTrBzMwMgiAgMTFR8jgAkJycjNmzZyMkJARWVlYQBAGHDh2SJVZ2djYiIiLQq1cv2NvbQxAErFu3TpZYQMWPdSlERkZi0KBB8PLygiAIGDFihGyxNm/ejKFDh8LX1xeCIKBbt26yxfrzzz8xatQo+Pn5wdDQEC+99JJssU6ePIlx48YhICAAxsbGEARBtlh16hijSli8eDEBoISEhMr8W423dOlSsra2ptzcXHFaTEwMAaCYmBit8sHBwRQcHFzh+SclJZGjoyM1atSIvv/+e1qwYAHZ2dmRv78/5efnS7AE/ycsLIyMjIxoxowZtGrVKgoKCiIjIyP6+++/dZ4nAHJ1daXQ0FACQBEREaWWc3BwoFatWtHcuXNpzZo1NGnSJDIxMaFmzZpRTk6OzvFLs3LlSgJAAwYMoNWrV9OwYcMIAC1cuFDSOLV925Xmjz/+IEEQKCQkhFavXk0TJ04kAwMD+vDDDyWNk5WVRb6+vuTs7EyLFi2ib7/9ljw9PcnDw4MeP34saayoqCgyMDAgPz8/atOmjaznKfW5wdfXl4KCgso8T0ghISGBAJCXlxd169aNAFBUVJQssYgqfqxLwdvbm+zt7alXr15kZGRE4eHhssUKDg4mS0tLCgkJITs7u0qdvysrPDyczMzMqFOnTuTh4UHe3t6yxYqIiCBjY2MKCAigJk2aUCW/0iulLh1j9Tbxyc7OFv9u3bo1DR06VONzKROfsWPHkkKhoDt37ojT9u/fTwBo1apVla57WU6cOEEAaPHixeK03NxcatSoEQUFBek8X/X2Tk1NfeHJsLR1tX79egJAa9as0Tn+83JycsjBwYH69OmjMX3IkCFkYWFB6enpksWq7duuNC1atCB/f3969uyZOO2TTz4hQRDo6tWrksVZtGgRAaCTJ0+K065evUqGhoY0Z84cyeIQEaWlpVFmZiYRyX+eyszMpLS0NCIi2rJli6yJT15eHiUnJxMR0alTp2RPfCp6rEshMTGRVCoVERFZWFjImvjcvXuXioqKiIioZcuWsiY+9+/fp4KCAiIi6tOnj6yJT0pKivijcvz48bImPnXpGKvwra558+Zh5syZAAAfHx+xjUvJS12//PILAgICoFAoYG9vj7CwMCQlJWnMp1u3bvDz88OVK1cQEhICc3NzNGjQAF9//bVWzGXLlqFly5YwNzeHnZ0d2rdvj40bN2qUOXfuHHr37g1ra2tYWlri1VdfxT///KNRZt26dRAEAYcPH8a4cePg7OwMDw8PAEBCQgLi4uLQo0ePiq6KSvv999/Rt29feHl5idN69OiBJk2a4Ndff5Uszm+//QZDQ0OMGTNGnGZmZoZRo0bh+PHjWtuioip6qba0y8dvv/02gOLbRVKJiYlBWloaxo0bpzF9/PjxePr0KXbv3i1ZrNq+7Z535coVXLlyBWPGjIGRkZE4fdy4cSAi/Pbbb5LEAYqXKTAwEIGBgeK0Zs2a4dVXX5V03QGAvb09rKysJJ1nWaysrGBvb6+XWKampnB1ddVLLKDix7oUvL29Zb01U5Knp6dWMwa5uLu7w9jYWC+xXFxcoFAo9BKrLh1jFd4T+vfvj8GDBwMAli5diujoaERHR8PJyQlA8b3h4cOHw9fXF99++y2mTJmCAwcOoGvXrlptPJ48eYJevXrB398f33zzDZo1a4ZZs2Zhz549Ypk1a9Zg0qRJaNGiBb777jt89tlnaNOmDU6cOCGWuXz5Ml555RVcuHABH330EebOnYuEhAR069ZNo5zauHHjcOXKFfz73//G7NmzARS3WwKAdu3aVXRVVMr9+/fx6NEjtG/fXuuzl19+GefOnZMs1rlz59CkSRNYW1trxQGA8+fPSxarolJSUgAAjo6Oks1Tvc6eX6cBAQEwMDCQbJ3WxW1X1rpzd3eHh4eHZMukUqkQFxdX5rq7desWsrKyJInFGGOVYVR+kWKtW7dGu3btsGnTJrz11lsavwzu3LmDiIgIzJ8/Hx9//LE4vX///mjbti1+/PFHjekPHjzAzz//jGHDhgEARo0aBW9vb/z000/o3bs3AGD37t1o2bIltmzZUmadPv30Uzx79gxHjhwRGx8PHz4cTZs2xUcffYTDhw9rlLe3t8eBAwdgaGgoTrt27RqA4qtYckhOTgYAuLm5aX3m5uaG9PR05Ofnw9TUVJJYZcUBite7vi1atAiGhoYYOHCgZPNMTk6GoaEhnJ2dNaabmJjAwcFBsuWsi9uuvGWSKo563ZS3TE2bNpUkHmOMVZQk1/62bt0KlUqFd955B48fPxZfrq6u8PX1RUxMjEZ5S0tLDB06VHxvYmKCl19+WeNpD1tbW9y7dw+nTp0qNWZRURH+/PNPvPXWWxpPXLm5ueFf//oXjhw5gszMTI3/GT16tEbSAwBpaWkwMjKCpaWlzsv/Irm5uQBQ6pejmZmZRhkpYukjTkVt3LgRP/30E6ZPnw5fX1/J5pubmwsTE5NSPzMzM5N0fQJ1a9uVt0y1cd0xxlhlVPiKz4vcuHEDRFTml9vz9zs9PDy07u3a2dkhLi5OfD9r1iz89ddfePnll9G4cWP07NkT//rXv9C5c2cAQGpqKnJyckr9xdi8eXOoVCokJSWhZcuW4nS5ruq8iPr+a35+vtZneXl5GmWkiKWPOBXx999/Y9SoUQgNDcWCBQsknbdCoUBBQUGpn+Xl5Um6PoG6te3KW6aavO5yc3OhVCo1psnV/qWgoADp6eka05ycnLR+OEmhqKhIq3sEe3v7MpP7qlLfflazsbGR7dyQmpqKoqIi8b2lpaVsPzLT09M1zgsKhQI2NjayxFIqlRqJu4mJiWxtUrKzs5GdnS2+NzQ0FJuYSK2uHmPPk+SKj0qlgiAI2Lt3L/bv36/1WrVqlUb5shaMiMS/mzdvjvj4ePz3v/9Fly5d8Pvvv6NLly6IiIjQuZ6lHdwODg4oLCyUrb2B+rK++hZDScnJybC3t5fkVok6VllxgOJ2HPpw4cIF9OvXD35+fvjtt980GtFKwc3NDUVFRXj06JHG9IKCAqSlpUm2nHVx25W3TFLFUa8bKZdp8+bNcHNz03jJ5dixY1qxpGpg/rykpCStWOq2h3J4PtbmzZtlixUYGKgRa8mSJbLF6t+/v0asyZMnyxZr8uTJGrH69+8vW6wlS5ZoxCr5sIDU6uox9rxKfSOV1QK/UaNGICL4+PigSZMmklQMACwsLPDuu+/i3XffRUFBAfr3748FCxZgzpw5cHJygrm5OeLj47X+79q1azAwMICnp2e5MZo1awag+Omu1q1bS1Z3tQYNGsDJyUmj52e1kydPok2bNpLFatOmDWJiYpCZmanRSFbd0FvKWGW5desWevXqBWdnZ/zxxx+y/LpTL8fp06fx+uuvi9NPnz4NlUol2XLWxW1Xct2pG04Dxe1t7t27p/FUWVUYGBigVatWpa67EydOoGHDhpV+QiQ0NFS2Dh2f5+/vrxVLrl++rq6uWrH8/f1liQVAK1bJq+JS27Bhg8aVkec7gpXSN998gydPnojv5fyh99FHH2k017Czs5Mt1vDhw9GlSxfxvZxX7uvqMfa8SiU+FhYWAKD1lFb//v0xZ84cfPbZZ/jll180EiQiQnp6OhwcHCpVsbS0NI3/MTExQYsWLbBnzx48e/YMZmZm6NmzJ7Zv347ExESxsfXDhw+xceNGdOnSResJmdIEBQUBKP4ikCPxAYABAwZg/fr1SEpKEpOxAwcO4Pr165g6dapkcQYOHIglS5Zg9erVYo/S+fn5iIqKQocOHSqUCFZFSkoKevbsCQMDA+zbt0+2y7Hdu3eHvb09IiMjNRKfyMhImJubo0+fPpLFqmvbrmXLlmjWrBlWr16NDz74QLz6GhkZCUEQJG2EPnDgQMyePRunT58Wn+6Kj4/HwYMHK9zjeUly/wItyc7OTtYuLkoyMzPTWywAeo2lbpqgDwEBAXqL1aJFC7Ro0UIvsRo2bChrwlhSXT3GnlepxEe9Y33yyScICwuDsbEx3njjDTRq1Ajz58/HnDlzkJiYiLfeegtWVlZISEjAtm3bMGbMmEqf6Hr27AlXV1d07twZLi4uuHr1KpYvX44+ffqIvxTnz5+P/fv3o0uXLhg3bhyMjIywatUq5Ofnl9ovUGkaNmwIPz8//PXXX3jvvfcqVceK+vjjj7FlyxaEhIRg8uTJyM7OxuLFi9GqVSuMHDlSo6w6gdOlK/AOHTpg0KBBmDNnDh49eoTGjRtj/fr1SExMxE8//aRRdt68efjss88QExNTbvft0dHRuHPnDnJycgAAsbGxmD9/PgBg2LBh8Pb2BgD06tULt2/fxkcffYQjR47gyJEj4jxcXFzw2muvie9HjBiB9evXIyEhodJ9hygUCnzxxRcYP348Bg0ahNDQUPz999/45ZdfsGDBAo177YcOHUJISAgiIiJ06n6/tm+70ixevBj9+vVDz549ERYWhkuXLmH58uV4//330bx5c7FcYmIifHx8EB4ertMwCePGjcOaNWvQp08fzJgxA8bGxvj222/h4uKC6dOna5Tt1q0bDh8+rHG7uzKUSqU4ZMnRo0cBAMuXL4etrS1sbW0xYcIEsWxV9j019f5/+fJlAMXHiHp///TTT8VyVd1W6uXIyMgQn7jbuXMn7t27BwCYOHGi2I5l3bp1GDlyJKKionQe/qGix3pVjyv1cly4cAEA8OzZM8TFxYmx+vXrJ/4Qrep+qF6O2NhYAMXtjp4+fSrG6tq1K7p27SqWFQQBwcHBOg+REBcXhx07dgAAbt68CaVSKcby9/fHG2+8IZatyjkDKH6iOjo6GgDEq6vqWN7e3uKT0wAfYxoq2+PhF198QQ0aNCADAwOtnht///136tKlC1lYWJCFhQU1a9aMxo8fT/Hx8WKZ4OBgatmypdZ8w8PDNXq4XLVqFXXt2pUcHBzI1NSUGjVqRDNnziSlUqnxf2fPnqXQ0FCytLQkc3NzCgkJoWPHjmmUiYqKIgB06tSpUpfp22+/JUtLS41hFaTsuZmI6NKlS9SzZ08yNzcnW1tbGjJkCKWkpGiVc3R0pI4dO1Zq3iXl5ubSjBkzyNXVlUxNTSkwMJD27t2rVW769OkV7qk3ODiYAJT6Krl+yioDQGt9DRgwgBQKBT158kTnZV29ejU1bdqUTExMqFGjRrR06VKxJ1i1nTt3EgBauXKlznFq87Yry7Zt26hNmzZkampKHh4e9Omnn4q9zapdvHiRANDs2bN1jpOUlEQDBw4ka2trsrS0pL59+9KNGze0ygUEBJCrq6vOcdRDO5T2er7nXCn2vRft6yVJsa28vb3LjFXy/Lts2TICUOo+U1EVPdalOK7Cw8PLjFWyd2op9sOIiIgyY5XsnTorK4sAUFhYmM6x1N83pb2e7526qucM9fdURc65fIyVmLfOtapDMjIyyN7entauXStOU+9Q//vf/yg1NVWje//g4GDq1KkTpaamaiViVXH58mUCQLt27ZJsnmUJDAykgQMHyh6nLM7OzjRjxgzZ48ycOZM8PDwoLy9P1jh1cdutWLGCLCwsSk3ypJSZmUlGRka0fPlyWeOo6WvfI9LvcTZo0CAKDAzUSyx9HVdE+tsPiYh2795NgiBQXFyc7LH0ec7gY0wTJz7/38KFC6lp06bieC7PZ9IlrxaV/FX0/HhRVbF8+XLJx2UqjVKpJBMTE7py5YrssUpz6dIlsrKyotTUVNljtW/fXtIxtcpSF7fdwIEDJR9TqzS7du0ib29vyQd9LY0+9z19biuVSkVOTk60b98+2WMR6e+4ItLffkhENGPGDBo8eLBeYunrnEHEx9jzBCIdb/jVcU+ePMGZM2fE9x06dBDbFp05c0Z8esDJyUnWJzAYY4wxJh1OfBhjjDFWb+hnuFrGGGOMsRqAEx/GGGOM1Ruc+DDGGGOs3uDEhzHGWJ0xZcoUCIIAQRBkGxCV1W6c+LA6a8GCBejXrx9cXFwgCILOPcxWRGRkJAYNGgQvLy8IgqBzz7kVsXnzZgwdOhS+vr4QBEHnHoEr4s8//8SoUaPg5+cHQ0NDnXthrYiTJ09i3LhxCAgIgLGxcZljA0ohPj4eU6dORadOnWBmZgZBEHTuPbc8ycnJmD17NkJCQmBlZQVBEHTuFbg82dnZiIiIQK9evWBvbw9BEHTu7bgiauIxNmzYMERHR+OVV16RrS6sduPEh9VZn376KU6dOoW2bdvKHmvRokU4ePAgWrZsKflo9M+LjIzE9u3b4enpKevgiACwceNGbNy4ETY2NrIO+ggAf/zxB9auXQtBEGQfm+j48eP44YcfkJWVpTFMhxzi4+OxaNEi3L9/H61atZI11uPHj/H555/j6tWreulmoyYeYwEBARg6dKjexrditQ8nPqzOSkhIQHJyMn755RfZYx0+fBiPHz/Gnj17YGpqKmus6OhoKJVKHDx4UPZk5Msvv0RmZiaOHj0q+xfp2LFjoVQqcfr0aY1x3eTQr18/ZGRk4OLFixgyZIissQICApCWlobr169j2rRpssZyc3NDcnIy7ty5g8WLF8saC6i7xxir2+T9acpYNZLztszz1IM36oNUI7VXhNyJVUkuLi56i1VyIFu5qTs+1QdTU1O4urrqLV5dPcZY3cZXfBhjjDFWb3DiwxhjjLF6gxMfxhhjjNUb3MaH1WopKSka721sbKBQKGSJlZqaiqKiIvG9paWlbP2EpKeno6CgQHyvUChgY2MjSyylUonc3FzxvYmJiWxtYLKzs5GdnS2+NzQ0hJOTkyyxcnNzoVQqNabJ1f6loKAA6enpGtOcnJxgaGgoeayioiKkpqZqTLO3t4eJiYnksYC6e4yx+ouv+LBazc3NTeO1efNm2WIFBgZqxFqyZIlssfr3768Ra/LkybLFmjx5skas/v37yxZryZIlGrECAwNli7V582at/UMux44d04qVlJQkS6ykpCStWMeOHZMlFlB3jzFWf/EVH1ar7d+/X+N9y5YtZYu1YcMGjSsjcvYT8s033+DJkyfiezmfrvroo48wdOhQ8b2cfQMNHz4cXbp0Ed/LdeUAAEJDQ7X2D7n4+/trxZLr6pKrq6tWLDm7GqirxxirvzjxYbVajx499Barc+fOeosVEBCgt1gtWrRAixYt9BKrYcOGevsyk/sqT0l2dnZ62xfNzMz0ut/X1WOM1V+c+LA6Kzo6Gnfu3EFOTg4AIDY2FvPnzwdQ3K29ul+QQ4cOISQkBBERETp3ub9z505cuHABAPDs2TPExcWJsfr164fWrVsDABITE+Hj44Pw8HCdhxKIjY1FbGwsgOI2EU+fPhVjde3aFV27dhXLCoKA4OBgnYdIiIuLw44dOwAAN2/ehFKpFGP5+/vjjTfeEMuq+3TRdeiHO3fuIDo6GgBw+vRpABBjeXt7Y9iwYWLZbt264fDhwyAinWIplUosW7YMAHD06FEAwPLly2FrawtbW1tMmDBBLDtixAisX78eCQkJOvdbo16Oy5cvAyjeN48cOQKguPdjtXnz5uGzzz5DTEyMzkORLF++HBkZGXjw4AGA4n3z3r17AICJEyeKbcXWrVuHkSNHIioqSuchVmriMfYiUmxLVgcQY3VUcHAwASj1FRMTI5bbuXMnAaCVK1fqHCs8PLzMWFFRUWK5ixcvEgCaPXu2zrEiIiLKjBURESGWy8rKIgAUFhamc6yoqKgyY4WHh2uUdXR0pI4dO+ocKyYmpsxYwcHBGmUDAgLI1dVV51gJCQllxvL29tYoO2DAAFIoFPTkyROd45UV6/lT8PTp00kQBLp69arOsby9vcuMlZCQIJZbtmwZAaC9e/fqHKsmHmMly1tYWGhMk2JbstqPEx9W782cOZM8PDwoLy9P9lgrVqwgCwsLSklJkT3W7t27SRAEiouLkz3W5cuXCQDt2rVL9liZmZlkZGREy5cvlz0WEZGzszPNmDFDL7ECAwNp4MCBeok1aNAgCgwM1EssfR5j2dnZlJqaSmFhYVqJjz63Jau5+FYXq/diYmIwd+5cvYz/ExMTg0mTJulleIaYmBiEhYXJPjCmOlZQUBD69Okje6zY2Fg0aNAAo0ePlj3W5cuXkZubi1mzZskeKzMzExcuXMD69etlj0VEOHTokF7G2AL0e4x98skn+P777wEAFhYW4nR9bktWswlEOt4kZ4wxxmqY69ev4+7duwAAIyMjndtKsbqLEx/GGGOM1RvcgSFjjDHG6g1OfBhjjDFWb3DiwxhjjLF6o84mPiNGjIAgCBAEAX5+ftVdHcYYY4zVAHU28QEAR0dHREdHY+HChRrT//zzT4waNQp+fn4wNDQsswfPxMREMXl6/vXf//5X0rp269at1Di9evXSeZ4nT57EuHHjEBAQAGNjYwiC8MLyP/30E5o3bw4zMzP4+vqKPdvqavPmzRg6dCh8fX0hCEK5T1ecPXsW/fr1g729PczNzeHn54cffvhB5/gLFixAv3794OLiAkEQyuwxdtu2bQgNDYW7uztMTU3h4eGBgQMH4tKlSzrHLotSqcRHH30EX19fKBQKeHt7Y9SoUeJTKLrKysrCRx99BB8fH5iamqJBgwYYOHCg2KOu2pkzZ9C3b1+4urrC0tISrVu3xg8//KAxIrYUkpOTMXv2bISEhMDKygqCIOjce3R5srOzERERgV69esHe3h6CIOjcK3ZFVHS/kkJkZCQGDRoELy8vCIKgcw/LFVHZ47UqKnoOlkJlz4NVER8fj6lTp6JTp04wMzODIAg692ReHj7GdFen+/GxsLDQGHxRbePGjdi8eTPatWtXocEfBw8ejNdff11jWlBQkGT1VPPw8MBXX32lMa0qg1P+8ccfWLt2LVq3bo2GDRvi+vXrZZZdtWoVPvzwQwwYMADTpk3D33//jUmTJiEnJ0fnfi8iIyNx5swZBAYGIi0t7YVl//zzT7zxxhto27Yt5s6dC0tLS9y6dUvsal8Xn376KVxdXdG2bVvs27evzHIXL16EnZ0dJk+eDEdHR6SkpOA///kPXn75ZRw/flyyASBVKhVee+01XLlyBePGjUOTJk1w8+ZN/Pjjj9i3bx+uXr0KKyurSs9XqVQiODgY9+7dw5gxY9C4cWOkpqbi77//Rn5+PszNzQEUJz2dOnWCr68vZs2aBXNzc+zZsweTJ0/GrVu3xL5PpBAfH49FixbB19cXrVq1wvHjxyWb9/MeP36Mzz//HF5eXvD395ft5K9W0f1KCosWLUJWVhZefvllJCcnyxqrMsdrVVX2HFwVlTkPVtXx48fxww8/oEWLFmjevDnOnz8vWyw+xqqgWrtPlFF4eLhW1/Nq9+/fp4KCAiIi6tOnT5nl1N3aL168WKZa/p/g4GBq2bKlpPNMSUmhnJwcIiIaP368Vvf4ajk5OeTg4EB9+vTRmD5kyBCysLCg9PR0neLfvXuXioqKiIioZcuWWsMOqCmVSnJxcaG3335bLC8Fdff8qampWsM5lCclJYWMjIzogw8+kKw+R48eJQBaPQ7/5z//IQC0detWneY7duxYsrW1pdu3b7+w3OjRo8nExITS0tI0pnft2pWsra11il2WzMxMMc6WLVu0hjCQUl5eHiUnJxMR0alTp8ocwkAqVdmvKisxMZFUKhUREVlYWGgNEyKlih6vUqjoOVgKFT0PSiEtLY0yMzOJiGjx4sVaw4RIiY8x3dXpW11lcXd3h7GxcaX+5+nTpygoKJCpRv+nsLAQ2dnZkszLxcUFCoWi3HIxMTFIS0vDuHHjNKaPHz8eT58+xe7du3WK7+npCQOD8nexjRs34uHDh1iwYAEMDAzw9OlTqFQqnWKWVJXL587OzjA3N0dGRkaV66GWmZkJAFq9NqtHEK/ItnpeRkYGoqKiMGbMGPj4+KCgoAD5+fllxjczM4Otra1WfF1iv4iVlRXs7e0lnWdZTE1N4erqqpdYQNX2q8ry9vaW9dZMSRU9XqWgyzlYVxU9D0rB3t5ep6u2uuBjTHf1MvGprM8++wyWlpYwMzNDYGAg/vzzT1niXL9+HRYWFrCysoKrqyvmzp2LZ8+eyRKrpHPnzgEA2rdvrzE9ICAABgYG4udy+euvv2BtbY379++jadOmsLS0hLW1NcaOHYu8vDxZY5eUkZGB1NRUXLx4Ee+//z4yMzPx6quvSjb/9u3bw8LCAnPnzsXBgwdx//59HD58GB999BECAwPRo0ePSs/zyJEjyMvLQ+PGjTFw4ECYm5tDoVCgc+fOWpfZu3XrhszMTHzwwQe4evUq7ty5g5UrV2Lr1q2YM2eOREvJGGM1W51u41NVBgYG6NmzJ95++200aNAAt2/fxrfffovevXtjx44dko5L1KhRI4SEhKBVq1Z4+vQpfvvtN8yfPx/Xr1/H5s2bJYtTmuTkZBgaGsLZ2VljuomJCRwcHPDgwQNZ49+4cQOFhYV48803MWrUKHz11Vc4dOgQli1bhoyMDGzatEnW+GodO3ZEfHw8AMDS0hKffvopRo0aJdn8HR0dsXnzZowePVojoQoNDcVvv/0GI6PKH443btwAAMyZMweNGjXCzz//DKVSic8++wzdu3fH5cuXxStKo0ePxuXLl7Fq1SqsXbsWAGBoaIjly5fjww8/lGAJGWOs5uPE5wW8vLy0GlYNGzYMLVq0wPTp0yVNfH766SetOGPGjMGaNWswdepUdOzYUbJYz8vNzYWJiUmpn5mZmSE3N1e22EDxEwM5OTn48MMPxae4+vfvj4KCAqxatQqff/45fH19Za0DAERFRSEzMxO3b99GVFQUcnNzUVRUJOnlfycnJ7Rt2xYTJkxAy5Ytcf78eXz99dcYOXIktmzZUun5qW+LCoKAAwcOwNLSEgDQtm1bBAUFYcWKFZg/fz6A4iSnUaNGCA0NxaBBg2BmZoZNmzZh4sSJcHV1xVtvvSXZcjLGWE3FiU8l2dvbY+TIkVi4cCHu3bsHDw8P2WJNnz4da9aswV9//SVr4qNQKMpsv5SXlyf7/XH1/AcPHqwx/V//+hdWrVqF48eP6yXxKfmkXlhYGJo3bw4AWLJkiSTzv337NkJCQvDzzz9jwIABAIA333wTL730EkaMGIE9e/agd+/elZqnet298cYbYtIDFF+98vHxwbFjx8RpCxcuxPfff48bN26IZd955x2EhIRg/Pjx6Nu3b6WuOhUUFCA9PV1jmpOTEwwNDSu1DBVRVFSE1NRUjWn29vZlJuxVlZKSovHexsZGtuMgNTVVozsBS0tLjW0ppfT0dI1jXaFQwMbGRpZYSqVS40eTiYmJbG1SsrOzNdpGGhoawsnJSZZYubm5UCqVGtPkav/Cx5g8uI2PDjw9PQFAa4esrXHc3NxQVFSER48eaUwvKChAWlqa7I+bquf/fKNf9a23J0+eyBq/NHZ2dujevTs2bNgg2TzXrVuHvLw89O3bV2N6v379AABHjx6t9DzLWndA8forue5+/PFHdO/eXetLtV+/fnjw4EGl+xs5duwY3NzcNF5JSUmVXoaKSEpK0opVMqmT2vOx5LzdHBgYqBFLqkS7NP3799eINXnyZNliTZ48WSNW//79ZYu1ZMkSjViBgYGyxdq8ebPW/iEXPsbkwVd8dHD79m0AkO0Xhb7jtGnTBgBw+vRpjf6KTp8+DZVKJX4ul4CAAOzfv19s3Kymblsk9/KXpbRfdlXx8OFDEJFWZ4HqBuyFhYWVnmdAQAAA4P79+1qfPXjwAM2aNdOIX1pHhbrG9/f3x/79+zWmyfXL19XVVSuWVP0rleb5WC1btpQt1oYNGzSujDRs2FC2WN98841GMiznj5qPPvpIox81Ozs72WINHz4cXbp0Ed/LeeUgNDRUa/+QCx9j8uDE5wVSU1O1vnTv37+P//znP2jdurVkmX5mZiZMTU1hamoqTiMisW1GaGioJHHK0r17d9jb2yMyMlIj8YmMjIS5ubmkbZlK884772DhwoX46aef0L17d3H62rVrYWRkJGsPsgDw6NEjrYbdiYmJOHDggNaTblXRpEkTEBF+/fVXjR541Y2327ZtW+l5Nm3aFP7+/ti+fTseP34MR0dHAMUdQiYlJWHixIka8ffv34+0tDQ4ODgAKL68/euvv8LKygqNGjWqVGw7OzudnkTThZmZmd5iAdBrrM6dO+stljpR1ocWLVqgRYsWeonVsGFDWRPGkuS+ylMSH2PyqJeJT1xcHHbs2AEAuHnzJpRKpZhk+Pv744033gBQ/Ivl1q1bePXVV+Hu7o7ExESsWrUKT58+1erldt26dRg5ciSioqIq3a382bNnMXjwYAwePBiNGzdGbm4utm3bhqNHj2LMmDFo166dRnlBEBAcHFxu75l37txBdHQ0gOKrNwDE5fT29sawYcMAFP86+uKLLzB+/HgMGjQIoaGh+Pvvv/HLL79gwYIFGvflDx06hJCQEERERJTbjXhsbCxiY2MBFCeRT58+FeN37doVXbt2BVD8hf/ee+/hP//5DwoLC8Vl27JlC+bMmaPxq3TevHn47LPPEBMTU25CFB0djTt37ojDNsTGxorxhw0bBm9vbwBAq1at8Oqrr6JNmzaws7PDjRs38NNPP+HZs2daw52MGDEC69evR0JCQqX7mhgxYgSWLFmCDz74AOfOnUPLli1x9uxZrF27Fi1btsTbb78tlq3Mel66dClee+01dOnSBR988AGUSiW+/fZbNGnSBGPHjhXLzZ49G0OHDkWHDh0wZswYKBQKbNq0CWfOnMH8+fM1+lWpynKqqdf15cuXARRvjyNHjgAo7plVrTLbtCzLly9HRkaGeJVw586dYq/fEydOFNuxVOU4VavoflWZbViWnTt34sKFCwCKr8zFxcWJsfr164fWrVsDKE7UfXx8EB4ervNQAhU9XoGKn4PKUtFzMPB/fbroOvRDRc+DQHGXD4cPHwYR6RRLqVSKQ/2ob10vX74ctra2sLW1xYQJE8SyfIyVTfZjTNLuEGuQF/XcHBUVRQBKfZXsGXXjxo3UtWtXcnJyIiMjI3J0dKS3336bzpw5ozXPZcuWEQDau3dvpet6+/ZtGjRoEL300ktkZmZG5ubmFBAQQCtXrhR7bVXLysoiABQWFlbufGNiYspcztJ6ZV29ejU1bdqUTExMqFGjRrR06VKt+Dt37iQAtHLlynLjR0RElBn/+Z44CwoKaN68eeTt7U3GxsbUuHFjWrp0qdY8p0+fToIg0NWrV8uNHxwcXGb8kj2cRkREUPv27cnOzo6MjIzI3d2dwsLCKC4uTmueAwYMIIVCQU+ePCk3fmnu3btH7733Hvn4+JCJiQm5ubnR6NGjKTU1VaNcZdYzEdH+/fupY8eOZGZmRvb29jRs2DCxp9WS9u7dS8HBweTo6EgmJibUqlWrUmNUdTmJqMx1//xppzLbtCze3t5lxirZc25VjlO1iu5Xld2GpQkPDy8zVsmecy9evEgAaPbs2TrHqujxWplzUFkqeg4mInJ0dKSOHTvqHKsy58GAgABydXXVOZa6t//SXs9/H/ExVja5j7E6nfh4enpSampqlXasiho0aBAFBgbKHmf37t0kCEKpX8r6MHPmTPLw8KC8vLxqiR8YGEgDBw6slthERM7OzjRjxgzZ41T3etbXchLpd5vq6zgl0u82XLFiBVlYWFBKSorssfR5Drp8+TIBoF27dskeKzMzk4yMjLSGlJELH2NVp+sxVqcTH3WGKPUYWM9TqVTk5ORE+/btkzUOEdGMGTNo8ODBsscpS/v27WnVqlXVElupVJKJiQlduXKlWuJfunSJrKystK7OyKE617M+l1Of21SfxymRfrfhwIEDac6cOXqJpc9z0PLlyykoKEgvsXbt2kXe3t6Un58veyw+xqSh6zEmEOl4M7OGu3Llingv0tLSUtZ+cBhjjDFWO9TZxIcxxhhj7HncgSFjjDHG6g1OfBhjjDFWb3DiwxhjjLF6gxMfxhhjdcaUKVMgCAIEQZBtsFdWu3Hiw+qsBQsWoF+/fnBxcYEgCDr3nlsRkZGRGDRoELy8vCAIgs49llbE5s2bMXToUPj6+kIQBFmH9Pjzzz8xatQo+Pn5wdDQUOceZivi5MmTGDduHAICAmBsbAxBEGSLFR8fj6lTp6JTp04wMzODIAg69wxcnuTkZMyePRshISGwsrKCIAg693hcnuzsbERERKBXr16wt7eHIAg69+RcETXxGBs2bBiio6PxyiuvyFYXVrtx4sPqrE8//RSnTp3SaQysylq0aBEOHjyIli1bwshI3pFgIiMjsX37dnh6eso68CMAbNy4ERs3boSNjY2sA1oCwB9//IG1a9dCEATZx106fvw4fvjhB2RlZaF58+ayxoqPj8eiRYtw//59tGrVStZYjx8/xueff46rV6/KOsCkWk08xgICAjB06FC9jd3Fah9OfFidlZCQgOTkZPzyyy+yxzp8+DAeP36MPXv2aAw2K4fo6GgolUocPHhQ9mTkyy+/RGZmJo4ePSr7F+nYsWOhVCpx+vRpvPbaa7LG6tevHzIyMnDx4kUMGTJE1lgBAQFIS0vD9evXMW3aNFljubm5ITk5GXfu3MHixYtljQXU3WOM1W31cpBSVj/IeVvmeepB8/TB09NTb7HkTqxKcnFx0VuskgPvys3KykpvsUxNTeHq6qq3eHX1GGN1G1/xYYwxxli9wYkPY4wxxuoNTnwYY4wxVm9wGx9Wq6WkpGi8t7GxgUKhkCVWamoqioqKxPeWlpay9ROSnp6OgoIC8b1CoYCNjY0ssZRKJXJzc8X3JiYmsrWByc7ORnZ2tvje0NAQTk5OssTKzc2FUqnUmCZX+5eCggKkp6drTHNycoKhoaHksYqKipCamqoxzd7eHiYmJpLHAuruMcbqL77iw2o1Nzc3jdfmzZtlixUYGKgRa8mSJbLF6t+/v0asyZMnyxZr8uTJGrH69+8vW6wlS5ZoxAoMDJQt1ubNm7X2D7kcO3ZMK1ZSUpIssZKSkrRiHTt2TJZYQN09xlj9xVd8WK22f/9+jfctW7aULdaGDRs0rozI2U/IN998gydPnojv5Xy66qOPPsLQoUPF93L2DTR8+HB06dJFfC/XlQMACA0N1do/5OLv768VS66rS66urlqx5OxqoK4eY6z+4sSH1Wo9evTQW6zOnTvrLVZAQIDeYrVo0QItWrTQS6yGDRvq7ctM7qs8JdnZ2eltXzQzM9Prfl9XjzFWf3Hiw+qs6Oho3LlzBzk5OQCA2NhYzJ8/H0Bxt/bqfkEOHTqEkJAQRERE6Nzl/s6dO3HhwgUAwLNnzxAXFyfG6tevH1q3bg0ASExMhI+PD8LDw3UeSiA2NhaxsbEAittEPH36VIzVtWtXdO3aVSwrCAKCg4N1HiIhLi4OO3bsAADcvHkTSqVSjOXv74833nhDLKvu00XXoR/u3LmD6OhoAMDp06cBQIzl7e2NYcOGiWW7deuGw4cPg4h0iqVUKrFs2TIAwNGjRwEAy5cvh62tLWxtbTFhwgSx7IgRI7B+/XokJCTo3G+NejkuX74MoHjfPHLkCIDi3o/V5s2bh88++wwxMTE6D0WyfPlyZGRk4MGDBwCK98179+4BACZOnCi2FVu3bh1GjhyJqKgonYdYqYnH2ItIsS1ZHUCM1VHBwcEEoNRXTEyMWG7nzp0EgFauXKlzrPDw8DJjRUVFieUuXrxIAGj27Nk6x4qIiCgzVkREhFguKyuLAFBYWJjOsaKiosqMFR4erlHW0dGROnbsqHOsmJiYMmMFBwdrlA0ICCBXV1edYyUkJJQZy9vbW6PsgAEDSKFQ0JMnT3SOV1as50/B06dPJ0EQ6OrVqzrH8vb2LjNWQkKCWG7ZsmUEgPbu3atzrJp4jJUsb2FhoTFNim3Jaj9OfFi9N3PmTPLw8KC8vDzZY61YsYIsLCwoJSVF9li7d+8mQRAoLi5O9liXL18mALRr1y7ZY2VmZpKRkREtX75c9lhERM7OzjRjxgy9xAoMDKSBAwfqJdagQYMoMDBQL7H0eYxlZ2dTamoqhYWFaSU++tyWrObiW12s3ouJicHcuXP1Mv5PTEwMJk2apJfhGWJiYhAWFib7wJjqWEFBQejTp4/ssWJjY9GgQQOMHj1a9liXL19Gbm4uZs2aJXuszMxMXLhwAevXr5c9FhHh0KFDehljC9DvMfbJJ5/g+++/BwBYWFiI0/W5LVnNJhDpeJOcMcYYq2GuX7+Ou3fvAgCMjIx0bivF6i5OfBhjjDFWb3AHhowxxhirNzjxYYwxxli9wYkPivt2EAQBgiDAz8+vuqvDGGOMMZlw4vP/OTo6Ijo6GgsXLhSn5eTkYMWKFejZsyfc3NxgZWWFtm3bIjIyUmMgPaC44zF18lTaS91JmlSOHTuGLl26wNzcHK6urpg0aZLG4I9S+uuvv9C9e3fY2NjAysoKAQEBsozX89NPP6F58+YwMzODr6+v2MGc1K5evYpevXrB0tIS9vb2GDZsmNagj1LIz8/HrFmz4O7uDoVCgQ4dOsg2hMKOHTvQrl07mJmZwcvLCxERESgsLJQ8zv379/HOO+/A1tYW1tbWePPNN3H79m3J46hUKnz99dfw8fGBmZkZWrdujU2bNkkeBwAWLFiAfv36wcXFBYIg6NzBXkVERkZi0KBB8PLygiAIOnccWBGbN2/G0KFD4evrC0EQZG3k++eff2LUqFHw8/ODoaGhrJ0Dnjx5EuPGjUNAQACMjY0hCIJsseLj4zF16lR06tQJZmZmEARB5w46y5OcnIzZs2cjJCQEVlZWEARB545Hy5OdnY2IiAj06tUL9vb2EARB5w5VK0Kfx1iFVOvD9DVEeHi4VqdlRMWdzQmCQD169KCvv/6aVq5cSW+//TYBoOHDh2uUvXDhAkVHR2u9PD09yc7OjvLz8yWr77lz58jMzIzatm1LkZGR9Mknn5CpqSn16tVLshhq//nPf0gQBOrZsyctX76cIiMjacqUKbR48WJJ46xcuZIA0IABA2j16tU0bNgwAkALFy6UNE5SUhI5OjpSo0aN6Pvvv6cFCxaQnZ0d+fv7S7qNiIjCwsLIyMiIZsyYQatWraKgoCAyMjKiv//+W9I4f/zxBwmCQCEhIbR69WqaOHEiGRgY0IcffihpnKysLPL19SVnZ2datGgRffvtt+Tp6UkeHh70+PFjSWPNnj2bANDo0aNp9erV1KdPHwJAmzZtkjQOUXHngq6urhQaGqrVCaTUvL29yd7ennr16kVGRkZanUBKKTg4mCwtLSkkJITs7Oy0OoGUUnh4OJmZmVGnTp3Iw8Oj1POpVCIiIsjY2JgCAgKoSZMmWp1ASikqKooMDAzIz8+P2rRpo9UJpJTUHXj6+vpSUFCQVieQUlJ34Onl5UXdunUrsxNIqejzGKtQfao1eg1RVuKTmppKly5d0po+cuRIAkA3btx44Xzv3r1LgiDQ6NGjpaoqERH17t2b3NzcSKlUitPWrFlDAGjfvn2SxUlISCCFQkGTJk2SbJ6lycnJIQcHB+rTp4/G9CFDhpCFhQWlp6dLFmvs2LGkUCjozp074rT9+/cTAFq1apVkcU6cOEEANBLE3NxcatSoEQUFBUkWh4ioRYsW5O/vT8+ePROnffLJJ1XuAfh5ixYtIgB08uRJcdrVq1fJ0NCQ5syZI1mce/fukbGxMY0fP16cplKp6JVXXiEPDw8qLCyULBYRiV9kqampsp+UExMTSaVSERGRhYWFrInP3bt3qaioiIiIWrZsKWvic//+fSooKCAioj59+sia+KSkpFBOTg4REY0fP17WxCctLY0yMzOJiGjx4sWyJj6ZmZmUlpZGRERbtmyRNfHJy8uj5ORkIiI6deqU7ImPPo+xiuBbXS/g6OhY6kjEb7/9NoDiWyYvsmnTJhARhgwZIlmdMjMzsX//fgwdOhTW1tbi9OHDh8PS0hK//vqrZLFWrlyJoqIifP755wCKL4+SDL0fxMTEIC0tDePGjdOYPn78eDx9+hS7d++WLNbvv/+Ovn37wsvLS5zWo0cPNGnSRNJ199tvv8HQ0BBjxowRp5mZmWHUqFE4fvw4kpKSJIlz5coVXLlyBWPGjIGR0f/1Rzpu3DgQEX777TdJ4gDFyxQYGIjAwEBxWrNmzfDqq69Kuu62b9+OZ8+eaewPgiBg7NixuHfvHo4fPy5ZLAB6HbPJ29tb1lszJXl6esLAQD+neHd3dxgbG+sllouLCxQKhV5i2dvbw8rKSi+xrKysYG9vr5dYpqamcHV11UssQL/HWEVw4qODlJQUAMWJ0Yts2LABnp6eGoNGVtXFixdRWFiI9u3ba0w3MTFBmzZtcO7cOcli/fXXX2jWrBn++OMPeHh4wMrKCg4ODpg7dy5UKpVkcdR1fn6ZAgICYGBgINky3b9/H48ePdKKAwAvv/yypOvu3LlzaNKkiUZyqo4DAOfPn5csDqC97tzd3eHh4SHZMqlUKsTFxZW57m7duoWsrCxJYp07dw4WFhZo3ry5Vhz154wxpitOfCqpoKAA3333HXx8fDR++T7v8uXLiIuLw+DBgyX9hZecnAwAcHNz0/rMzc1NHJFZCjdu3EBSUhJGjhyJ9957D7/99ht69+6N+fPn45NPPpEsTnJyMgwNDeHs7Kwx3cTEBA4ODpItU3nrLj09Hfn5+ZLFKisOAL0tk1Rx1OtGX8ukbgQpZxzGWP3EY3VV0oQJE3DlyhXs3r1b49bC8zZs2AAAkt7mAoDc3FwAKHXMGzMzM/FzKWRnZ0OlUmHhwoXi+DYDBgxAeno6vv/+e3z88ceSXAbOzc2FiYlJqZ9JuUzlrTt1GSnGEyprPiXjSKG8ZcrMzNRLnJJlpIiljziMsfqJE59KWLx4MdasWYMvvvgCr7/+epnliAgbN26En58fWrduLWkd1Pe2S7sykZeXJ+m9b4VCgadPn2Lw4MEa0wcPHoy9e/fi3LlzktzGUygUKCgoKPUzKZepvHVXsowUsfQVB5B/f6jt6059e1rNxsZGtnYiqampGt1dWFpawtLSUpZY6enpGseOQqGAjY2NLLGUSqVG0mliYiJbm5Ts7GyN7jkMDQ3h5OQkS6zc3FwolUqNaXK1fykoKEB6errGNCcnJxgaGkoeq6ioSKubDnt7+zJ/ZFaVPo+xquJbXRW0bt06zJo1Cx9++CE+/fTTF5Y9evQo7ty5I/nVHuD/Lverb3GUlJycDHd3d8liqef1/Eji6ltST548kSSOm5sbioqK8OjRI43pBQUFSEtLk2yZylt39vb2ko0e7ebmVmYcAHpbJqniqNeNvpYpJSVFqyF9VeK4ublpvOToh0otMDBQI9aSJUtki9W/f3+NWJMnT5Yt1uTJkzVi9e/fX7ZYS5Ys0Yj1omYFVbV582at/UMux44d04ol1YMOz0tKStKKdezYMVliAfo9xqqKr/hUwPbt2/H++++jf//+WLFiRbnlN2zYAEEQ8K9//Uvyuvj5+cHIyAinT5/GO++8I04vKCjA+fPnNaZVVUBAAG7cuIH79++jYcOG4nR1GwupfoG1adMGAHD69GmNK2mnT5+GSqUSP6+qBg0awMnJCadPn9b67OTJk5LFAYqXKSYmBpmZmRoNnE+cOCF+LlUcoHhdqRv/AsXb6N69expPlVWFgYEBWrVqVeq6O3HiBBo2bCjZ0y9t2rTB2rVrcfXqVbRo0UIjjvrzynq+48jSntaUyoYNGzSujJQ8dqT2zTffaPwAkfKHz/M++ugjDB06VHxvZ2cnW6zhw4ejS5cu4ns5rxyEhobK1rHo8/z9/bViyXV1ydXVVSuWv7+/LLEA/R5jVVatD9PXEGX140NEdPjwYTIzM6OQkBDKy8srd14FBQXk4OBAr7zyisS1/D+9evUiNzc3sX8JIqK1a9cSANqzZ49kcbZt20YA6OOPPxanFRUVUZcuXcje3r5C66MicnJyyN7envr27asxfejQoWRubi72bSGFDz/8kBQKBd29e1ec9tdffxEAioyMlCzOP//8o9WPT15eHjVu3Jg6dOggWRwiombNmpG/v79G/zaffvopCYJAV65ckSzOwoULCQCdOnVKnHbt2jUyNDSkWbNmSRYnKSmpzH58GjRoIHk/Pmr67mNE7n58SpK7H5+S5O7HpyS5+/EpSe5+fEqSux+fkvTRj49aTenHhxMfKjvxSUxMJBsbG1IoFLRixQqtXpkvXLig9T87d+4kALRy5coy40VFRVVpRztz5gyZmppq9NxsZmZGPXv21CoLQOcTnkqloldffZUEQaAxY8bQihUr6LXXXiu1s7/w8PAqnRRWrFhBAGjgwIG0Zs0aGj58OAGgBQsWaJRT926q64Fz9+5dcnBwoEaNGtEPP/xAX375JdnZ2VGrVq20Ejlvb+8qncAHDRpERkZGNHPmTFq1ahV16tSJjIyM6PDhwxrlIiIiqnSS27lzJwmCQN27d6fVq1fTpEmTyMDAQKvjTHVvrbp+2WZmZlKjRo3I2dmZvv76a1q6dCl5enqSu7s7PXr0SKNscHBwlb6QZs6cSQBozJgxtGbNGrHn5g0bNmiUq+qxRET0888/0xdffEFz5swhABQSEkJffPEFffHFF5SYmCiWq+q+R0S0Y8cOcd4mJibUtm1b8X3J80lVtxVR8Y829bydnZ3ppZdeEt8/vw9W5TxBVNxzvXreTZs2JVtbW/H9jh07NMpW9bhKTEwU592hQwcCIL7/+eefNcpWdT/MyMgQ592rVy8CQNOnT6cvvviCli1bplG2qudAIhJjhYWFEQB67733xGklVfWcQUS0bNky+uKLL2js2LEEgPr37y/GysjIEMvVtmOsIjjxobITH/VGKOtV2sYJCwsjY2PjF16lWLZsGQGgvXv36lznv//+mzp16kRmZmbk5ORE48eP17gCRFQ8xAAACgsL0zlOVlYWTZ48mVxdXcnExIRatWpFv/zyi1a5AQMGkEKhoCdPnugca/Xq1dS0aVMyMTGhRo0a0dKlS8VebtUqkliW59KlS9SzZ08yNzcnW1tbGjJkCKWkpGiVc3R0pI4dO+ocJzc3l2bMmEGurq5kampKgYGBpW7z6dOnV7mX5W3btlGbNm3I1NSUPDw86NNPPxV70lW7ePEiAaDZs2frHCcpKYkGDhxI1tbWZGlpSX379i21B/OAgABydXXVOU5RURF9+eWX5O3tTSYmJtSyZctS9zspjiX1l2Npr5JfLFLse+ovx9JeJb9YpNhW6i/H8s5dUpwn1F+Opb2eT96qely96Lz8fPJW1f1QnYCW9nr+O0OKc+CLvm9KkuKc4e3tXWaskslbbTvGKoITHyo+GXl6elJqamqVdtqKGjRoEAUGBsoeZ/fu3SQIAsXFxckey9nZmWbMmCF7nJkzZ5KHh4dkt9nKcvnyZQJAu3btkjUOEVFgYCANHDhQ9jgrVqwgCwuLUpM8KWVmZpKRkREtX75c1jhE+juWiPS37xHpb1sR6fc8oc/jSp/7IZH+zoFE+jtnENXNY4wTH9L8FdayZUtZY6lUKnJycpJ0TK2yzJgxgwYPHix7nEuXLpGVlRWlpqbKHqt9+/aSjqlVluXLl0s+plZplEolmZiYSNoWpywDBw6UdEytsuzatYu8vb0lH/T1efo8loj0t+8R6W9bEenvPEGkv+OKSH/7IZF+z4H6PGfU1WNMIJJh8KVa5sqVK+KTSpaWlujYsWM114gxxhhjcuDEhzHGGGP1BndgyBhjjLF6gxMfxhhjjNUbnPgwxhhjrN7gxIcxxlitNWXKFAiCAEEQNAaDzcjIEKcLgqAxZtrs2bPRoUOH6qguqwE48WF1xoIFC9CvXz+4uLhAEATMmzdPtliRkZEYNGgQvLy8IAgCRowYIVuszZs3Y+jQofD19YUgCOjWrZtssf7880+MGjUKfn5+MDQ0xEsvvSRbrJMnT2LcuHEICAiAsbExBEGQLVZ8fDymTp2KTp06wczMDIIgIDExUZZYycnJmD17NkJCQmBlZQVBEHDo0CFZYmVnZyMiIgK9evWCvb09BEHAunXrZIkF1MxjbNiwYYiOjsYrr7yiMd3CwgLR0dFYunSp1v9MmTIFFy5cwI4dO+SoOqvhOPFhdcann36KU6dOoW3btrLHWrRoEQ4ePIiWLVvCyEjesX4jIyOxfft2eHp6yjowJABs3LgRGzduhI2NjawDXgLAH3/8gbVr10IQBFkH8gSA48eP44cffkBWVhaaN28ua6z4+HgsWrQI9+/fR6tWrWSN9fjxY3z++ee4evWqrANQqtXEYywgIABDhw7V2oeMjY0xdOhQvPXWW1r/4+rqijfffFPjKhCrPzjxYXVGQkICkpOT8csvv8ge6/Dhw3j8+DH27NkDU1NTWWNFR0dDqVTi4MGDsicjX375JTIzM3H06FHZv0jHjh0LpVKJ06dP47XXXpM1Vr9+/ZCRkYGLFy9iyJAhssYKCAhAWloarl+/jmnTpskay83NDcnJybhz5w4WL14sayygbh1j77zzDo4cOYLbt29LPm9Ws3Hiw+oMOW/LPM/b21vWWzMleXp6wsBAP4equ7s7jI2N9RLLxcUFCoVCL7Hs7e1hZWWll1hWVlawt7fXSyxTU1O4urrqJRZQt46xHj16AAC2b98uWwxWM3HiwxhjrN6xsbFBo0aNcPTo0equCtMzTnwYY4zVSw0bNsSVK1equxpMzzjxYYwxVi/Z2dnh8ePH1V0NpmfyPo7CmMRSUlI03tvY2MjWTiQ1NRVFRUXie0tLS41+QqSUnp6OgoIC8b1CoYCNjY0ssZRKJXJzc8X3JiYmsrVJyc7ORnZ2tvje0NAQTk5OssTKzc2FUqnUmCZX+5eCggKkp6drTHNycoKhoaHksYqKipCamqoxzd7eHiYmJpLHAuruMVYaItJbWz1Wc/AVH1aruLm5abw2b94sW6zAwECNWHI++tq/f3+NWJMnT5Yt1uTJkzVi9e/fX7ZYS5Ys0YgVGBgoW6zNmzdr7R9yOXbsmFaspKQkWWIlJSVpxTp27JgssYC6e4yV5smTJ3B0dNRrTFb9+IoPq1X279+v8b5ly5ayxdqwYYPGlRE5+5r55ptv8OTJE/G9nI+tf/TRRxg6dKj4Xs6+gYYPH44uXbqI7+V8iis0NFRr/5CLv7+/Viy5ri65urpqxZKzq4G6eoyVJiEhQS/9H7GahRMfVquoH0HVh86dO+stVkBAgN5itWjRAi1atNBLrIYNG+rty0zuqzwl2dnZ6W1fNDMz0+t+X1ePsecplUrcunULY8eOrbY6sOrBiQ+rM6Kjo3Hnzh3k5OQAAGJjYzF//nwAxd3ae3t7AwAOHTqEkJAQRERE6Nzl/s6dO3HhwgUAwLNnzxAXFyfG6tevH1q3bg0ASExMhI+PD8LDw3UeSiA2NhaxsbEAittEPH36VIzVtWtXdO3aVSwrCAKCg4N1HiIhLi5O7Mb/5s2bUCqVYix/f3+88cYbYll1ny66Dv1w584dREdHAwBOnz4NAGIsb29vDBs2TCzbrVs3HD58GESkUyylUolly5YBgPj48vLly2FrawtbW1tMmDBBLDtixAisX78eCQkJOvdbo16Oy5cvAyjeN48cOQKguPdjtXnz5uGzzz5DTEyMzkORLF++HBkZGXjw4AGA4n3z3r17AICJEyeKbcXWrVuHkSNHIioqSuchVmriMaarv/76C0SEN998s0rzYbUQMVZHBAcHE4BSXzExMWK5nTt3EgBauXKlzrHCw8PLjBUVFSWWu3jxIgGg2bNn6xwrIiKizFgRERFiuaysLAJAYWFhOseKiooqM1Z4eLhGWUdHR+rYsaPOsWJiYsqMFRwcrFE2ICCAXF1ddY6VkJBQZixvb2+NsgMGDCCFQkFPnjzROV5ZsZ4/5U6fPp0EQaCrV6/qHMvb27vMWAkJCWK5ZcuWEQDau3evzrFq4jFWsryFhYXWdPW2X7x4scb0d999l7p06aJz/VjtxYkPq3dmzpxJHh4elJeXJ3usFStWkIWFBaWkpMgea/fu3SQIAsXFxcke6/LlywSAdu3aJXuszMxMMjIyouXLl8sei4jI2dmZZsyYoZdYgYGBNHDgQL3EGjRoEAUGBuollj6PsezsbEpNTaWwsDCNxEelUlFqaiqdPXtWK/FJTk4mMzMz+t///id7/VjNw7e6WL0TExODuXPnyj7GljrWpEmT4OLiopdYYWFhsg+MqY4VFBSEPn36yB4rNjYWDRo0wOjRo2WPdfnyZeTm5mLWrFmyx8rMzMSFCxewfv162WMREQ4dOqSXMbYA/R5jn3zyCb7//nsAxSOyqymVyjK7Tvjuu+/QqlUrvs1VTwlEOt40Z4wxxqrZ9evXcffuXQCAkZGR2FaqsLBQo61bkyZN4OXlVQ01ZDUNJz6MMcYYqze4A0PGGGOM1RuyJz4rVqzASy+9BDMzM3To0AEnT56UOyRjjDHGWKlkTXw2b96MadOmISIiAmfPnoW/vz9CQ0Px6NEjOcMyxhhjjJVK1jY+HTp0QGBgIJYvXw4AUKlU8PT0xMSJEzF79uwX/q9KpcKDBw9gZWXFg8gxxhhjtQQRISsrC+7u7jAwqHktamR7nL2goABnzpzBnDlzxGkGBgbo0aMHjh8/rlU+Pz8f+fn54vv79+/rrVt9xhhjjEkrKSkJHh4e1V0NLbIlPo8fP0ZRUZFW/yUuLi64du2aVvmvvvoKn332mdb0pKQkWFtby1VNxhhjjEkoMzMTnp6esLKyqu6qlKrGdGA4Z84cTJs2TXyvXnHW1tac+DDGGGO1TE1tpiJb4uPo6AhDQ0M8fPhQY/rDhw/h6uqqVd7U1FQvvXwyxhhjrP6SrdWRiYkJAgICcODAAXGaSqXCgQMHEBQUJFdYxhhjjLEyyXqra9q0aQgPD0f79u3x8ssv47vvvsPTp08xcuRIOcMyxhhjjJVK1sTn3XffRWpqKv79738jJSUFbdq0wd69e/UyYCNjjDHG2PNq7FhdmZmZsLGxgVKp5MbNjDHGWC1R07+/a17PQowxxhhjMuHEhzHGGGP1Bic+jDHGGKs3OPFhjDHGWL3BiQ9jjDHG6g1OfBhjjDFWb3DiwxhjjLF6gxMfxhhjjNUbnPgwxhhjrN7gxIcxxhhj9QYnPowxxhirNzjxYYwxxli9wYkPY4wxxuoNTnwYY4wxVm9w4sMYY4yxeoMTH8YYY4zVG5z4MMYYY6ze4MSHMcYYY/UGJz6MMcYYqzc48WGMMcZYvcGJD2OMMcbqDU58GGOMMVZvcOLDGGOMsXqDEx/GGGOM1Ruc+DDGGGOs3jCq7gqw2qugoABPnz6t1P8IggBLS0sYGfGuxxhjTP/424fpbM+ePViyZAmIqML/Y2FhgYULF6Jt27Yy1owxxhgrHSc+TGcpKSk4evRopRIfS0tLJCYmwtPTE7a2tnzlhzHGmF7p1Mbnq6++QmBgIKysrODs7Iy33noL8fHxGmXy8vIwfvx4ODg4wNLSEgMGDMDDhw8lqTSrvXJycjB79myEhYXh2rVr1V0dxhhj9YxOic/hw4cxfvx4/PPPP9i/fz+ePXuGnj17arT3mDp1Knbu3IktW7bg8OHDePDgAfr37y9ZxVntpFKpcP36dZw9exaJiYlITk5GYWFhdVeLMcZYPSFQZe5TlCE1NRXOzs44fPgwunbtCqVSCScnJ2zcuBEDBw4EAFy7dg3NmzfH8ePH0bFjx3LnmZmZCRsbGyiVSlhbW1e1ikwGq1atwtixYyt1q0vN0NAQ3t7e8Pb2xurVq9G4cWMZasgYY0zfavr3tySPsyuVSgCAvb09AODMmTN49uwZevToIZZp1qwZvLy8cPz48VLnkZ+fj8zMTI0Xq9msra3RsGFDcbtXRlFREW7fvo3r168jLy9Phtoxxhhj2qqc+KhUKkyZMgWdO3eGn58fgOJGryYmJrC1tdUo6+LigpSUlFLn89VXX8HGxkZ8eXp6VrVqTGavv/469uzZg9GjR1d3VRhjjLEKqfIjNePHj8elS5dw5MiRKs1nzpw5mDZtmvg+MzOTk58aTp2kNmvWDC1atHhhWZVKhXv37iE7O1tj+rNnz3Dr1i2YmZnB29sbxsbGclaZMcZYPVelxGfChAnYtWsXYmNj4eHhIU53dXVFQUEBMjIyNK76PHz4EK6urqXOy9TUFKamplWpDqsmAwYMQPfu3V9YJj8/H2PHjsWBAwc0pqelpeHDDz9E48aNsWHDBnh5eclZVcYYY/WcTokPEWHixInYtm0bDh06BB8fH43PAwICYGxsjAMHDmDAgAEAgPj4eNy9exdBQUFVrzWrUaysrGBlZfXCMgUFBWjZsiVSU1Nx+/Zt8cpPUVERUlJSYGRkhLi4OOTk5KBRo0Z85YcxxpgsdHqqa9y4cdi4cSO2b9+Opk2bitNtbGygUCgAAGPHjsUff/yBdevWwdraGhMnTgQAHDt2rEIxanqrcFZ5T548QVpaGsLDw7X2A0NDQ9jb28PPzw+bNm2Ci4tLNdWSMcZYVdT072+drvhERkYCALp166YxPSoqCiNGjAAALF26FAYGBhgwYADy8/MRGhqKH3/8sUqVZbWbnZ0dTE1N0bZtWxQUFODatWsaV35SU1ORmpqKoqKiaq4pY4yxukqSfnzkUNMzRqYbIkJWVhYePnyIsLAwnD17VuNzPz8/7Nu3D+7u7tVUQ8YYY1VR07+/JenHh7GKEgQB1tbWsLe3L3WcrpycHBw7dgxnz57lHp0ZY4xJjhMfVqMkJiZi5MiRmDFjBrKysqq7OowxxuqYejM09qVLl5CUlFTd1WD/X2ZmJjIyMrSmq1QqZGdn48GDB9i/f3+5T4uxusXBwQEBAQEwNDSs7qowxuqoepH4EBFWrlyJqKio6q4K+/+ICPn5+WV+fuPGDYwYMQKCIOixVqy6BQcH49dff4WlpWV1V4UxVkfVi8QHKO5HJicnp7qrwSpIpVIhNze3uqvB9IzHbWOMyY3b+DDGGGOs3uDEhzHGGGP1Bic+jDHGGKs36kUbH0EQ8Morr5T5eV5eHvbu3YvU1NQKzc/b2xvdu3fX6ocmLi4OJ06ceOH/GhoaokePHnBzc8O+ffuQnp6OXr16wdnZuUKxy3PmzBmtTgGfZ2xsjJ49e1a5k8CrV6/iyJEj4vuAgAC0a9fuhf/z7Nkz7Nu3D8nJyS8s5+zsjNDQUJiZmQEA7ty5g7/++gsqlQoA0KxZM3Tp0qVKjZ+zs7Oxd+9ePHnypELlGzdujODgYMTHx+PIkSPw8/OTfOy5R48eYe/evS9s+A1AjP389u7SpQuaNm2KQ4cO4datWy+ch7W1NXr37o3CwkLs2bNHbAPn7u6Onj17Vmm8tMLCQhw4cAB37959YTl7e3v07t0b5ubmAIq3K4/TxhiTFdVQSqWSAJBSqZRkfiqVqszXo0ePqH379gSgQq9+/fpRTk6O1nwWL15c7v+amprSjh07KCMjg7p160YODg70zz//vLB+lXnNnTu33DpYWVnRgQMHqhwrMjKSBEEQ5ztv3rxy/0e93OXVsUOHDpSamir+37Zt28jU1FT8fMyYMVRYWFil+iclJZGfn1+Ft/vgwYOpoKBAXO6pU6dSUVGRZNtOpVLRsWPHyN7evty6qGOX3N6CINCqVasoPz+fwsLCyp1Ho0aN6ObNm3T+/Hlyc3MTp4eEhJBSqazScuTk5FCfPn3KrYOfnx8lJSVp/C9jrHaT+vtbavXiig+AF14ZUCgUGDx4MPz9/fG///0PaWlppZbz8PDAG2+8gXbt2sHY2Fhrni+KIQgCQkND0bJlS/j4+MDMzAwDBgxAUFAQ3NzcJHtsu6LzMTAwqHLM1q1bY9KkSaD/P+pJx44dy52nermbNGmC7du34+HDh2WWFQRBnF/jxo0xYcIEPHv2DADQuXPnKvf1YmVlhSFDhuDatWvYtm0bMjMzSy3XsGFD9O7dGx06dIChoaG43MHBwTAwkPZucUW3i4GBAQwMDBAUFIRJkyYBKF5frVq1qtS2FQQBzs7OeP/996FUKgEAvr6+MDU1rdL+UXLblUeKfZExxiqq3iQ+L2JpaYlp06bh3r17OHHiRJmJj6+vLxYtWqRTp3qGhoYYPnw4Bg8eLE6bMGGCznWuCTp16oROnTpV6n9MTU0xYcIEPH78GOfPn39h4lOSn58flixZoks1y2RjY4PZs2fj1q1b+Pvvv8tMfNSx1bfddFluufTu3Ru9e/fWmFbZoT7c3Nzw+eefS1ktxhirsbhxcyXcvXsX3377LX7//XceQbyKyvuF/+DBA3z//ffYtGkTCgoK9FSr0lXm6gVjjLGajROfSrh16xbmzZuH6OhoHkBTZklJSfjiiy+wZs2aak98GGOM1R18q6uGu3fvHjZs2FDhXqcPHTpUbpn8/HxERUUhJiamQvP08fHBv/71L5iYmFSoPCvueXrr1q24ePFipf4vKSmJexhnjDEZceJTw92/fx+LFy8us92RLgoKCvDzzz9XuHxISAgGDBjAiU8lqBOfTZs2VXdVGGOMlcCJD4CcnBz89NNPuHLlClJSUqq7OgCAlJQUrF27FteuXcPTp0+rtS63bt3C3Llz0aZNGwwdOlSr/yKm6ffff8fx48dx7ty56q6KLGJjY7Fr164XliksLMSVK1f0VCPGGKs4/gZDceLzyy+/4OTJk9VdFdGjR48QGRmJBw8eVHdVcPfuXXz//ffo168fwsLC6lzio34cXwoqlQr79u3DmjVrJJtnTXPq1CksXry4uqvBGGM6qVvfYOVQqVT4+eefcfr0aY3peXl5SExMLPf/mzRpgjFjxqB58+ayffk/fvwYy5cvR3x8vNivSk0RFxeHqVOnomPHjhg2bFiZfdhs3boVBw8eBPB/j/EHBATIUqeDBw9i69atVZqHUqnE48ePq1yXrVu34q+//sLRo0erPK+a6MiRI9i8eXOdvZLFGKsf6l3i8+eff+rU7sLAwABeXl744IMPYGlpKUPtiuv35MkTrF+/vkKJWMnEg4h0unLx/KPa6iEhSpOYmIiVK1dCqVRi6NChWp+r6/D3339jxYoVAAAjIyN06NABbdu21ShbVFT0wlhA8fK9qJNClUqFs2fPirGqS8nljoyMrPD/PZ84lrc+qkPJOl26dAkrVqyQ7AqZevtyVwGMMX2qV4mPrho2bIjJkyejSZMmYid2UsvIyMC3336Lq1evVqghc4cOHfD++++LX5779u3Dr7/+WqmYlpaWmDJlCnx8fAAU31779ttvKzxm2fN27NiB7du3a9wyLCoqwpo1a/DXX39plC3vKlt56/zw4cOIjo6u9FNTcihtuctja2uLadOmoUGDBgCKn95bunQpMjIyZKpl5Z0/fx4rV64UuxOIj4+XLOlxcnLC9OnT0bRpU9jY2EgyT8YYqwhOfMphZGQENzc3DB06FPb29rLFyc7OxrZt23Dp0qUXlhMEAYaGhmjatClGjhwpXhFRKpXYtm1bha6kAMW3oCwtLdGvXz8EBgYCAG7fvo2oqCg8efKk3H6K1ENHlLwic/bsWURFRWmUIyIcOnSoQo/Zl+Tk5IQhQ4bAwcGh1M+vXbuG//znP5K2z9FVactdGvXVjaKiIpibm+ONN96An58fjIyMcOnSJfz000/IysqqMZ1j3rlzB+vWrSt3wNTnGRoaljuUh729Pd555x0x6WaMMX3hxOcFPD09MWfOHPj6+sp2e6uy2rVrhylTpqBx48YaXy6vv/463N3dsWXLFvz+++8vnIeZmRlmzpyJtm3bolGjRuJ0Z2dnfPPNN7h69Sq++uqrMkctP3bsGMLDw/Haa6/h/fffl2bB6jj1Ovfy8sLChQvx4MEDzJkzB02bNsXHH38MT09PLFu2DHFxcVi0aBGys7Oru8o6MTAwwLhx49C5c+cXlrOwsICTk5OeasUYY/+HE5/nmJiYiAmFi4sL3nrrLbi5uVVzrf6Ph4cHBg0aBFNTU43pTZs2RdOmTXHlypVyEx9jY2N0794d3bp105huaWmJvn37wtvbG999912Zic+dO3dw584d2NnZYdSoUZK20RAEASYmJqUOAqsLY2PjcgczValUePbsmaxXj9TrvFWrVlizZg1u3bqFvXv34saNG5g0aRKcnZ3Rr18/uLi44LvvvqvWxEe9PtRX9cpjZGQkNvY3MjJCly5d8M4778hZRcYY0xknPiXY29tj3rx58PLyAlA8iKWdnV0116p+8fLyQkREBBo3bqzTYLAlGRgYYNKkSXjllVdeWC4lJQUREREVHjC1rrt8+TIWLFiAhISECiU/w4YNw5tvvgmgeJ0/35CdMcZqEk58SjA1NUWHDh3g5+cHhULBT5tUkrGxMSwsLFBQUFDhqwVqgiBAoVDA1dUVvXv3hqura5XrY2BggICAAPFLuSy3bt3C119/XeV4FaFeTnNzc+Tl5aGoqAg5OTnIzc2VreF8ZaWmpmL37t3lXnUyNjaGiYkJ2rVrV+46ZoyxmoIHKS0hPT0dU6dOxfjx4/nXvw4GDx6MrVu3om/fvpX+X1dXV/z4449YunRpnb7KZmVlhUWLFmHNmjXw8vLCw4cPMXbsWEydOrXMW4s1VVhYGLZu3Yo33nijuqvCGGMVJknis3DhQgiCgClTpojT8vLyMH78eDg4OMDS0hIDBgyo9mRCEASYm5vDxsam1A4I8/PzcezYMRw6dAgPHz6EUqmEUqlEdnZ2qe0/nj17JpZRKpXIzc3Vx2LUWI0aNULPnj3x0ksvlVtWEARYWlrCxsYGNjY2cHFxQXBwMIKCgrTaL9UlxsbG6NChA0JCQuDq6gojIyMcO3YMf//9Nx49eoSsrKwa2Z9PaRo3boyePXvC29u7uqvCGGMVVuVbXadOncKqVavQunVrjelTp07F7t27sWXLFtjY2GDChAno379/tfZqa2BggBkzZiAsLAxz587FP//8U2q5lJQUvP/++zA3NwcAtGjRAosWLYK1tbVGucOHD+PLL78UHz++d++evAtQh1hbW2PRokVo3rw5AIi3ueoLBwcHLF++HDdu3MC0adNw584djBgxAvn5+cjKyqru6jHGWJ1VpcQnOzsbQ4YMwZo1azB//nxxulKpxE8//YSNGzeie/fuAICoqCg0b94c//zzDzp27Fi1WutIEAQ0a9YMPj4+8PHxwY0bN5CZmanVHiUvL09jWIunT58iJSVF7MhN7ebNm4iNjdVrvyv5+flITU2FjY2NRuPf3NxcPH36FDk5OTrPW6VSQalU4smTJy+86mBqagorK6syH/G3tLSEo6MjsrOzkZeXV2oZQ0ND+Pj4wM/PDzY2NuU+efU8hUIBR0dH8UpcTk5OlZZdbkSEjIwMpKWlwcbGBiYmJggICICtrS0UCgWSk5Nx4sSJ6q4mY4zVeVW61TV+/Hj06dMHPXr00Jh+5swZPHv2TGN6s2bN4OXlhePHj1clpCRMTEwwb948bNmyRetKVWmuXbuGwYMHo0+fPhqvJUuW6L2zuX/++Qdvv/02Fi9erBF727Zt6NOnDzZu3KjzvB88eIBRo0Zh/PjxL+w9ulu3btixYwcmTJhQagPw999/H7t27UJoaGiZ88jMzMTUqVMxfPhw3Llzp9J17d27N3bv3i2+Bg8eXOl56FNOTg7mzJmDwYMH4/r169VdHcYYq7d0vuLz3//+F2fPnsWpU6e0PktJSYGJiQlsbW01pru4uCAlJaXU+eXn52v0EJuZmalr1colCAKaNGkCd3d3+Pj44P79+0hLSyvzSaSnT5/i7NmzstUHKO7/xMnJCc7OzkhLSyszocrIyMDp06fh6emJBw8eiFdK4uPjKz26vEqlQnp6unglKykpCWfOnMHdu3df+H/29vZ4+eWXy7xK4+XlBU9PTzRp0gRubm7IyMjQav9UWFiIK1euQKlU6nSlxsnJSaMDvNjYWLi7u2uUMTQ0hEKhqPS8K8vKygru7u5QKpV4+vRpqWVUKhWuXbuGhw8fIjExUTw2Hj16VG4v2YwxxqSjU+KTlJSEyZMnY//+/ZI9gvvVV1/hs88+k2ReFWVubo5FixYhKSkJEyZMKHe4CDk5Ojpi5cqVuH79Oj788EPcv3//heVjYmI0np7SZXytzMxMTJkyRRzvqqCgoMzEtLIEQcCkSZMQFhaGTz/9FHv27JFkvmUZNmwYevbsqTVd3SeTPmIvWbIE0dHRLyybmZmJyZMni+3HpFznjDHGyqdT4nPmzBk8evQI7dq1E6cVFRUhNjYWy5cvx759+1BQUICMjAyNqz4PHz4sswHrnDlzMG3aNPF9ZmYmPD09dalehRkYGKBhw4aws7NDo0aNkJGRgYcPH1a6DxopGBkZiQNyNmrUCESEhw8fvvDKT1UHtCwqKsKNGzcQFxdXofIKhQLOzs5wdnauUHkPDw+4urpqXfkrqbCwEA8ePICtra34lJMuXFxc4OLiotP/VpU6dpMmTeDt7Y20tLQy+8ApKirCzZs39VzDylEoFPD29kZqaioePXpUZrmMjAwkJibC3t5eq+E/Y4zVVDq18Xn11Vdx8eJFnD9/Xny1b98eQ4YMEf82NjbGgQMHxP+Jj4/H3bt3ERQUVOo8TU1NYW1trfHSF2tra3z//ffYsGFDtT+a6+bmhqioKERGRpY5QGd16dixI3bs2IFZs2ZVujFyWdLS0vDBBx/gvffeq/VXPsaMGYM9e/agd+/e1V2VKvH398e2bdsQEREBExOTMstFR0ejV69e2Lp1qx5rxxhjVaPTz2srKyv4+flpTLOwsICDg4M4fdSoUZg2bZr4a3DixIkICgqqtie6XsTQ0BDe3t5QKBRo3ry5zl/q6enpOt1yKsnY2BgNGzZEYWEhmjRpAoVCgaSkpGrt28Xc3Bzu7u5o1qwZmjVr9sIvw+cJggB3d3c0adIE9+/f12oDU1hYiMTERBQVFeHatWsoLCyEh4eHzld+qpOzszOcnJzQrFkzNG3aFA8ePKiVj6abm5vD19cXV65ceWHv5Y8fP8bjx48RHx+P+Ph4nWKZmprW2u3NGKudZDvbLF26FAYGBhgwYADy8/MRGhqKH3/8Ua5wknBwcMDKlSu1HluvqNWrV+Orr76SpC4+Pj7YtGkTTp8+jZEjR1b5tlZVtG7dGmvWrIGzs3Olkh6gOKmcPXs2Ro8ejbFjxyImJqbUcsnJyRgxYgT8/Pzw888/V/h2Wk0jCAImT56M8PBwTJs2DTt27KjuKslu1apV+O9//6vT/zZt2rRWb2/GWO0jWeJz6NAhjfdmZmZYsWIFVqxYIVUI2RkaGmo9GVQZUt6aMjY2hoeHB548eYLWrVtXOPF5+PBhhXvINjQ0hK+vb5l97aj5+fmhYcOGYoPcynJ0dISlpSUsLCzKLFNYWIj79+9DoVAgLi4OL730Enx8fCS7paZPDg4OsLW1RfPmzZGYmFip/83JyUFCQoLeu0kojY2NDVq1aoVHjx698Em/J0+e6DzchpGRUa3f3oyx2oWvL9dwzZo1w+bNmyt8q2vJkiVYunRphcpaW1vju+++K/cKl6mpqV4eCweAxMREDB06FIGBgfj5559r7bhdhoaGmDVrFiZNmlSp/zt79iyGDx9eI8btUrfp+v333zFlyhRZkrG6sr0ZY7UHJz41nLGxcaWGcijZm3N5DAwM4OjoqEu1Ks3AwAC+vr4ICAjA9evXy2z7UlhYiIcPHyI1NbXWjFlVFjs7u0p/kSclJcHAoGaMHWxmZgY3Nzf4+voiMDAQKSkplb6CVZ66tL0ZY7VDzTjDsjqvsr1ls5qjW7du2LlzZ5k9dTPGWG3CV3wkkJycjJs3b+LWrVtlliEiXLt2DUeOHEGLFi1gb2+vxxrWDNbW1jAyMkL79u1RVFSEy5cva135sbCwgJ+fH9q2bQtjY+NqqikrydTUFKampmjSpAm6du0qjo+WmJhYbi/fZTEzM4Ofn5/GQMC8vRlj+sCJjwT27duHadOmaQ3LUFJRURGWLFmCVatWYf369S8cx6ouMzc3x/z58/Ho0SMMGjRIaygQb29vrFu3Dh4eHi9sDM30LzQ0FF27dhXff/nll/j66691mperqyvWrl2Ll156CUBxmyje3owxfeDEpwpSUlJw8eJFnDt3DhkZGeIv4bLk5OTg2bNnOHnypHjLwMTEBO3atZOsw8bGjRuXOnRDSebm5tXaiNTS0hIqlQqdO3fWamPk4+MDZ2fnMkd+l4O5uTleeeUVNG7cuNTP27Rpo7d2NzY2NggJCSl3rLqmTZuW+ZkgCGjduvULB5oFAHd390o9qWdiYqLRnYGfn1+5+9qLYru4uMDGxkan/2eMMV0JVN63dTXJzMyEjY0NlEplje0O/9dff8WYMWOQm5tbqb5/zMzMxMd2HRwcsHXrVgQEBEhSp2fPnmkM9loaAwMDmJmZVXsj2tzcXK0nhQwNDWFmZqbXtiREhNzc3DIb1xoZGUk2Jl15VCoV8vLyym3o+3wS8rz8/Pxyh14xMDCAQqHQeV1XZF+TKzZjrOaq6d/ffMWnClxdXdG9e3fcvn0bFy5cqPD/lew3x8zMTNLHhI2NjWtNWwl9PSJfHkEQdO6jSGoGBgaS1EXdLkdOtWlfY4wxNX6qqwq6dOmCTZs24f333+dfrowxxlgtwFd8XkCpVOLw4cNio2VnZ2e88sor4rhCBgYGMDU1FX/1Nm3aFG3atBH///z58+WOYVRQUIA///wTKSkpCA4OrlFtHtLS0hAbG6t1G8/b2xsdOnTgZI8xxlitw4nPCyQlJWHixIlITk4GAISEhCAwMLDMhrevv/46Fi1aJL6fOXNmuYlPVlYW5s2bBw8PD+zatatGJT63bt3C2LFjkZ6erjF98ODBCAwM5OEFGGOM1Tqc+JQiKysLe/fuxdWrV5GZmSk2Er179y5+/vlnNGnSBN27dxcbBzdr1gzvvfceOnbsqNHmISgoCJmZmTh27NgLE6CioiIUFhbKu1CV8OTJE+zbtw+XLl1Cdna2ViPZ+Ph4REVFoUWLFujUqVM11ZIxxhirPH6qqxS3b99GaGgobt++rfV0jYGBAfr164f//ve/Go1HVSoVBEHQuP1DRCgqKsLYsWOxdu3aF8Zs0KAB9u7dCz8/P2kXRgcXL17E66+/jvv375f5iL6BgQHGjBmDH3/8kW95McYYE/FTXbUQEUGlUpX6SLFKpcLNmzcRGRkptvXx8/NDt27dtMoePXoU58+fx5UrV8qMZWZmhr59+6Jp06aSju5eFQ4ODhg2bBhu3LiBXbt2lTp6u0qlwsWLF7FixQq0adMGXbp0qYaaMsYYY5XDV3xKcevWLfTs2RO3b9+uUPkPPvgAkZGRWlc+pk2bVu5I6Q4ODti9ezc6dOigc33l8s8//6BPnz5abXyeN336dCxZskRPtWKMMVaT8RWfWsjW1hajR49GfHw8tmzZgqdPn76w/Pnz50v94j916lSF4tXUW0Xu7u6YOHEicnJyAAA3btzAzp07tfodOnXqFBYvXgygeFm6deuG9u3b672+jDHGWHn4is8LXLx4Eb169cKDBw9ki+Hg4IA//vgDL7/8smwxpLJ9+3a8++675fbW++2332Lq1Kl6qhVjjLGapCZ8f78Id2D4As7Ozpg6dSpGjhwpeS/DJiYmGD58OGbOnAl3d3dJ5y2XZs2a4ZNPPsHbb79dY69SMcYYYy/Cic8LuLi4YMaMGfjggw8kH9LA1NQUI0eOxKxZs+Dh4SHpvOXStGlTzJ07FwMHDqz2cb4YY4wxXXAbnwrw9PTE3LlzxR6cr1y5go0bN+o0xpaRkRGGDBkCf39/NGzYUOqq6kWbNm3w5Zdfik+9xcbGYs+ePejRowdeffVVfsKLMcZYjcWJTwW4u7tj8uTJ4vsdO3Zgy5YtOic+AwcORN++faWsol61aNECLVq0EN8bGxtjz549eOWVVzB79uxqrBljjDH2Ypz46MDPzw+LFy8utZ+f8hgYGNSITgql1L17d3z//ffo2LFjdVeFMcYYeyF+qosxxhhjkqnp39/cQpUxxhhj9QYnPowxxhirNzjxYYwxxli9wYkPY4wxxuoNTnwYY4wxVm/onPjcv38fQ4cOhYODAxQKBVq1aoXTp0+LnxMR/v3vf8PNzQ0KhQI9evTAjRs3JKk0Y4wxxpgudEp8njx5gs6dO4sd1125cgXffPMN7OzsxDJff/01fvjhB6xcuRInTpyAhYUFQkNDkZeXJ1nlGWOMMcYqQ6d+fGbPno2jR4/i77//LvVzIoK7uzumT5+OGTNmAACUSiVcXFywbt06hIWFlRujpvcDwBhjjDFtNf37W6crPjt27ED79u0xaNAgODs7o23btlizZo34eUJCAlJSUtCjRw9xmo2NDTp06IDjx4+XOs/8/HxkZmZqvBhjjDHGpKRT4nP79m1ERkbC19cX+/btw9ixYzFp0iSsX78eAJCSkgKgeHTzklxcXMTPnvfVV1/BxsZGfHl6eupSNcYYY4yxMumU+KhUKrRr1w5ffvkl2rZtizFjxmD06NFYuXKlzhWZM2cOlEql+EpKStJ5XowxxhhjpdEp8XFzc9MYnRsAmjdvjrt37wIAXF1dAQAPHz7UKPPw4UPxs+eZmprC2tpa48UYY4wxJiWdEp/OnTsjPj5eY9r169fh7e0NAPDx8YGrqysOHDggfp6ZmYkTJ04gKCioCtVljDHGGNOdkS7/NHXqVHTq1Alffvkl3nnnHZw8eRKrV6/G6tWrAQCCIGDKlCmYP38+fH194ePjg7lz58Ld3R1vvfWWlPVnjDHGGKswnRKfwMBAbNu2DXPmzMHnn38OHx8ffPfddxgyZIhY5qOPPsLTp08xZswYZGRkoEuXLti7dy/MzMwkqzxjjDHGWGXo1I+PPiiVStja2iIpKYnb+zDGGGO1RGZmJjw9PZGRkQEbG5vqro4Wna746ENWVhYA8GPtjDHGWC2UlZVVIxOfGnvFR6VSIT4+Hi1atOCrPtVInbnzNqg+vA2qH2+D6sfboPpVdBsQEbKysuDu7g4Dg5o3FnqNveJjYGCABg0aAAA/3l4D8DaofrwNqh9vg+rH26D6VWQb1MQrPWo1LxVjjDHGGJMJJz6MMcYYqzdqdOJjamqKiIgImJqaVndV6i3eBtWPt0H1421Q/XgbVL+6sg1qbONmxhhjjDGp1egrPowxxhhjUuLEhzHGGGP1Bic+jDHGGKs3OPFhjDHGWL1RoxOfFStW4KWXXoKZmRk6dOiAkydPVneV6qx58+ZBEASNV7NmzcTP8/LyMH78eDg4OMDS0hIDBgzAw4cPq7HGtV9sbCzeeOMNuLu7QxAE/O9//9P4nIjw73//G25ublAoFOjRowdu3LihUSY9PR1DhgyBtbU1bG1tMWrUKGRnZ+txKWqv8tb/iBEjtI6JXr16aZTh9V81X331FQIDA2FlZQVnZ2e89dZbiI+P1yhTkXPP3bt30adPH5ibm8PZ2RkzZ85EYWGhPhel1qrINujWrZvWsfDhhx9qlKlN26DGJj6bN2/GtGnTEBERgbNnz8Lf3x+hoaF49OhRdVetzmrZsiWSk5PF15EjR8TPpk6dip07d2LLli04fPgwHjx4gP79+1djbWu/p0+fwt/fHytWrCj186+//ho//PADVq5ciRMnTsDCwgKhoaHIy8sTywwZMgSXL1/G/v37sWvXLsTGxmLMmDH6WoRarbz1DwC9evXSOCY2bdqk8Tmv/6o5fPgwxo8fj3/++Qf79+/Hs2fP0LNnTzx9+lQsU965p6ioCH369EFBQQGOHTuG9evXY926dfj3v/9dHYtU61RkGwDA6NGjNY6Fr7/+Wvys1m0DqqFefvllGj9+vPi+qKiI3N3d6auvvqrGWtVdERER5O/vX+pnGRkZZGxsTFu2bBGnXb16lQDQ8ePH9VTDug0Abdu2TXyvUqnI1dWVFi9eLE7LyMggU1NT2rRpExERXblyhQDQqVOnxDJ79uwhQRDo/v37eqt7XfD8+iciCg8PpzfffLPM/+H1L71Hjx4RADp8+DARVezc88cff5CBgQGlpKSIZSIjI8na2pry8/P1uwB1wPPbgIgoODiYJk+eXOb/1LZtUCOv+BQUFODMmTPo0aOHOM3AwAA9evTA8ePHq7FmdduNGzfg7u6Ohg0bYsiQIbh79y4A4MyZM3j27JnG9mjWrBm8vLx4e8gkISEBKSkpGuvcxsYGHTp0ENf58ePHYWtri/bt24tlevToAQMDA5w4cULvda6LDh06BGdnZzRt2hRjx45FWlqa+Bmvf+kplUoAgL29PYCKnXuOHz+OVq1awcXFRSwTGhqKzMxMXL58WY+1rxue3wZqGzZsgKOjI/z8/DBnzhzk5OSIn9W2bVAjByl9/PgxioqKNFYiALi4uODatWvVVKu6rUOHDli3bh2aNm2K5ORkfPbZZ3jllVdw6dIlpKSkwMTEBLa2thr/4+LigpSUlOqpcB2nXq+lHQPqz1JSUuDs7KzxuZGREezt7Xm7SKBXr17o378/fHx8cOvWLXz88cfo3bs3jh8/DkNDQ17/ElOpVJgyZQo6d+4MPz8/AKjQuSclJaXU40T9Gau40rYBAPzrX/+Ct7c33N3dERcXh1mzZiE+Ph5bt24FUPu2QY1MfJj+9e7dW/y7devW6NChA7y9vfHrr79CoVBUY80Yqx5hYWHi361atULr1q3RqFEjHDp0CK+++mo11qxuGj9+PC5duqTRtpDpV1nboGS7tVatWsHNzQ2vvvoqbt26hUaNGum7mlVWI291OTo6wtDQUKvl/sOHD+Hq6lpNtapfbG1t0aRJE9y8eROurq4oKChARkaGRhneHvJRr9cXHQOurq5ajf0LCwuRnp7O20UGDRs2hKOjI27evAmA17+UJkyYgF27diEmJgYeHh7i9Iqce1xdXUs9TtSfsYopaxuUpkOHDgCgcSzUpm1QIxMfExMTBAQE4MCBA+I0lUqFAwcOICgoqBprVn9kZ2fj1q1bcHNzQ0BAAIyNjTW2R3x8PO7evcvbQyY+Pj5wdXXVWOeZmZk4ceKEuM6DgoKQkZGBM2fOiGUOHjwIlUolnpiYdO7du4e0tDS4ubkB4PUvBSLChAkTsG3bNhw8eBA+Pj4an1fk3BMUFISLFy9qJKH79++HtbU1WrRooZ8FqcXK2walOX/+PABoHAu1ahtUd+vqsvz3v/8lU1NTWrduHV25coXGjBlDtra2Gq3GmXSmT59Ohw4dooSEBDp69Cj16NGDHB0d6dGjR0RE9OGHH5KXlxcdPHiQTp8+TUFBQRQUFFTNta7dsrKy6Ny5c3Tu3DkCQN9++y2dO3eO7ty5Q0RECxcuJFtbW9q+fTvFxcXRm2++ST4+PpSbmyvOo1evXtS2bVs6ceIEHTlyhHx9fWnw4MHVtUi1yovWf1ZWFs2YMYOOHz9OCQkJ9Ndff1G7du3I19eX8vLyxHnw+q+asWPHko2NDR06dIiSk5PFV05OjlimvHNPYWEh+fn5Uc+ePen8+fO0d+9ecnJyojlz5lTHItU65W2Dmzdv0ueff06nT5+mhIQE2r59OzVs2JC6du0qzqO2bYMam/gQES1btoy8vLzIxMSEXn75Zfrnn3+qu0p11rvvvktubm5kYmJCDRo0oHfffZdu3rwpfp6bm0vjxo0jOzs7Mjc3p7fffpuSk5Orsca1X0xMDAHQeoWHhxNR8SPtc+fOJRcXFzI1NaVXX32V4uPjNeaRlpZGgwcPJktLS7K2tqaRI0dSVlZWNSxN7fOi9Z+Tk0M9e/YkJycnMjY2Jm9vbxo9erTWDy9e/1VT2voHQFFRUWKZipx7EhMTqXfv3qRQKMjR0ZGmT59Oz5490/PS1E7lbYO7d+9S165dyd7enkxNTalx48Y0c+ZMUiqVGvOpTdtAICLS3/UlxhhjjLHqUyPb+DDGGGOMyYETH8YYY4zVG5z4MMYYY6ze4MSHMcYYY/UGJz6MMcYYqzc48WGMMcZYvcGJD2OMMcbqDU58GGOMMVZvcOLDGGOMsXqDEx/GGGOM1Ruc+DDGGGOs3uDEhzHGGGP1xv8DDphu5jAAXYgAAAAASUVORK5CYII="},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torchvision import models\n\n\n# model=models.resnet18(pretrained=True)\n# dummy_input=torch.rand(1,3,120,240)\n# o=torch.tensor(dummy_input)\n# for layer in list(model.children()):\n#     o=layer(o)\n#     print(f\"for the layer {layer}   output -shape={o.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:01:39.750612Z","iopub.execute_input":"2024-11-26T14:01:39.750989Z","iopub.status.idle":"2024-11-26T14:01:39.755362Z","shell.execute_reply.started":"2024-11-26T14:01:39.750955Z","shell.execute_reply":"2024-11-26T14:01:39.754497Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# model.named_children","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:01:43.017518Z","iopub.execute_input":"2024-11-26T14:01:43.018110Z","iopub.status.idle":"2024-11-26T14:01:43.022019Z","shell.execute_reply.started":"2024-11-26T14:01:43.018074Z","shell.execute_reply":"2024-11-26T14:01:43.021141Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"#\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\n#otal clasees without blank\nnum_classes=len(char_to_index)\n\nclass CRNN(nn.Module):\n    def __init__(self, num_classes, lstm_hidden_size=256, num_lstm_layers=2):\n        super(CRNN, self).__init__()\n        # Use ResNet18 for feature extraction\n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # 1x64x224 -> 32x64x224 #b,h,w\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),  # 32x64x224 -> 32x32x112\n            \n            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32x32x112 -> 64x32x112\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),  # 64x32x112 -> 64x16x56\n            \n            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # 64x16x56 -> 128x16x56\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),  # 128x16x56 -> 128x8x28\n        )\n        self.cnn_out_channels=128\n        \n        # LSTM for sequence modeling\n        self.lstm = nn.LSTM(\n            input_size=self.cnn_out_channels*8,\n            hidden_size=lstm_hidden_size,\n            num_layers=num_lstm_layers,\n            bidirectional=False,\n            batch_first=True\n        )\n        \n        \n        # Fully connected layer for character classification\n        self.fc = nn.Linear(lstm_hidden_size * 1, num_classes)  # Bidirectional LSTM doubles hidden size\n\n    def forward(self, images, labels=None):\n        # Extract features with CNN\n        features = self.cnn(images)  # (B, C, H, W)\n        batch_size, channels, height, width = features.size()\n        \n        # Reshape features for LSTM input\n        features = features.permute(0, 3, 1, 2)  # (B, W, C, H)\n        features = features.view(batch_size, width, -1)  # (B, W, C * H)\n        \n        # Pass through LSTM\n        lstm_out, _ = self.lstm(features)  # (B, W, 2 * hidden_size)\n        \n        # Pass through fully connected layer\n        output = self.fc(lstm_out)  # (B, W, num_classes)\n        \n        return output\n\n\nmodel=CRNN(num_classes+1).to(device=device) #+1 for the blank in ctc loss\nmodel_input=torch.rand(16,1,64,264).to(device)\nprint(model(model_input).shape)\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:16:06.322994Z","iopub.execute_input":"2024-11-27T09:16:06.323349Z","iopub.status.idle":"2024-11-27T09:16:06.361168Z","shell.execute_reply.started":"2024-11-27T09:16:06.323314Z","shell.execute_reply":"2024-11-27T09:16:06.360408Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 33, 100])\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# num_classes=len(char_to_index)\n# class CustomTextRecognitionModel(nn.Module):\n#     def __init__(self, num_classes, lstm_hidden_size=256, num_lstm_layers=2):\n#         super(CustomTextRecognitionModel, self).__init__()\n\n#         # Customized CNN layers to extract features from the image\n#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # (B, 32, H, W)\n#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # (B, 64, H, W)\n#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # (B, 128, H, W)\n#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)  # (B, 256, H, W)\n\n#         # Adding batch normalization for stability and dropout for regularization\n#         self.bn1 = nn.BatchNorm2d(32)\n#         self.bn2 = nn.BatchNorm2d(64)\n#         self.bn3 = nn.BatchNorm2d(128)\n#         self.bn4 = nn.BatchNorm2d(256)\n#         self.dropout = nn.Dropout(0.2)\n\n#         # LSTM for sequence modeling (bidirectional to capture context from both directions)\n#         self.lstm = nn.LSTM(\n#             input_size=int(256 * 224/(2**2)),  # Output channels from the last conv layer * height after pooling\n#             hidden_size=lstm_hidden_size,\n#             num_layers=num_lstm_layers,\n#             bidirectional=True,\n#             batch_first=True\n#         )\n\n#         # Fully connected layer for character classification\n#         self.fc = nn.Linear(lstm_hidden_size * 2, num_classes)  # Bidirectional LSTM doubles hidden size\n\n#     def forward(self, x):\n#         # Apply CNN layers with batch normalization and ReLU activation\n#         x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), kernel_size=2, stride=2)  # (B, 32, H/2, W/2)\n#         x = F.relu(self.bn2(self.conv2(x)))  # (B, 64, H/4, W/4)\n#         x = F.relu(self.bn3(self.conv3(x))) # (B, 128, H/8, W/8)\n#         x = F.avg_pool2d(F.relu(self.bn4(self.conv4(x))), kernel_size=2, stride=2)  # (B, 256, H/16, W/16)\n        \n#         # Apply dropout to reduce overfitting\n#         x = self.dropout(x)\n\n#         # Flatten the CNN output for LSTM input (batch, time_steps, features)\n#         batch_size, channels, height, width = x.size()\n#         x = x.view(batch_size, width, -1)  # (B, W, 256 * H/2)\n\n#         # Pass through LSTM\n#         lstm_out, _ = self.lstm(x)  # (B, W, 2 * hidden_size)\n\n#         # Pass through the fully connected layer\n#         output = self.fc(lstm_out)  # (B, W, num_classes)\n\n#         return output\n\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Instantiate the model\n# model = CustomTextRecognitionModel(num_classes + 1).to(device=device)  # +1 for blank token\n# model_input = torch.rand(16, 1, 224, 224).to(device)  # Example input size\n\n# # Print the model output shape\n# print(model(model_input).shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T17:15:28.968213Z","iopub.execute_input":"2024-11-26T17:15:28.968549Z","iopub.status.idle":"2024-11-26T17:15:29.302705Z","shell.execute_reply.started":"2024-11-26T17:15:28.968519Z","shell.execute_reply":"2024-11-26T17:15:29.301884Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 56, 101])\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# #\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torchvision import models\n\n# #otal clasees without blank\n# num_classes=len(char_to_index)\n\n# class CNN(nn.Module):\n#     def __init__(self, num_classes):\n#         super(CRNN, self).__init__()\n#         # Use ResNet18 for feature extraction\n#         self.model = models.resnet18(pretrained=True)\n#         self.model.conv1 = nn.Conv2d(\n#             1, 64, kernel_size=7, stride=2, padding=3, bias=False\n#         )\n#         self.cnn = nn.Sequential(*(list(self.model.children())[:-4]))  # Remove the FC and pooling layers\n        \n\n#     def forward(self, images, labels=None):\n#         # Extract features with CNN\n#         features = self.cnn(images)  # (B, C, H, W)\n#         batch_size, channels, height, width = features.size()\n        \n#         # Reshape features for LSTM input\n#         features = features.permute(0, 3, 1, 2)  # (B, W, C, H)\n#         features = features.view(batch_size, width, -1)  # (B, W, C * H)\n#         return features\n        \n\n# class RNN(nn.Module):\n#     def __init__(self, num_classes, lstm_hidden_size=256, num_lstm_layers=2):\n#         super(CRNN, self).__init__()\n#         self.cnn_out_channels = 512  # ResNet18 final convolutional layer output channels\n        \n#         # LSTM for sequence modeling\n#         self.lstm = nn.LSTM(\n#             input_size=self.cnn_out_channels*7,\n#             hidden_size=lstm_hidden_size,\n#             num_layers=num_lstm_layers,\n#             bidirectional=True,\n#             batch_first=True\n#         )\n        \n#         # Fully connected layer for character classification\n#         self.fc = nn.Linear(lstm_hidden_size * 2, num_classes)  # Bidirectional LSTM doubles hidden size\n\n#     def forward(self, features, labels=None):\n#         lstm_out, _ = self.lstm(features)  # (B, W, 2 * hidden_size)\n#         # Pass through fully connected layer\n#         output = self.fc(lstm_out)  # (B, W, num_classes)\n        \n#         return output\n\n\n\n# class CRNN_TOP(nn.Module):\n#     def __init__(self, num_classes, lstm_hidden_size=256, num_lstm_layers=2):\n#         super(CRNN, self).__init__()\n#         # Use ResNet18 for feature extraction\n#         self.top_cnn=CNN(num_classes)\n#         self.middle_cnn=CNN(num_classes)\n#         self.bottom_cnn=CNN(num_classes)\n#         self.lstm=RNN(lstm_hidden_size=256, num_lstm_layers=2)\n        \n\n#     def forward(self, images, labels=None):\n#         # Extract features with CNN\n#         features_top = self.cnn(images)  # (B,  W,C*H)\n#         features_middle = self.cnn(images)  # (B, W,C*H)\n#         features_bottom = self.cnn(images)  # (B, W,C*H)\n\n#         features=\n        \n        \n#         # Pass through LSTM\n#         lstm_out, _ = self.lstm(features)  # (B, W, 2 * hidden_size)\n        \n#         # Pass through fully connected layer\n#         output = self.fc(lstm_out)  # (B, W, num_classes)\n        \n#         return output\n\n\n# model=CRNN(num_classes+1).to(device=device) #+1 for the blank in ctc loss\n# model_input=torch.rand(16,1,224,224).to(device)\n# print(model(model_input).shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn import CTCLoss\nfrom torch.optim import Adam\nfrom torch.nn.functional import log_softmax\n\nloss_fn = CTCLoss(blank=0, reduction='mean', zero_infinity=False)\noptimizer = Adam(model.parameters(), lr=1e-3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:40:36.534115Z","iopub.execute_input":"2024-11-27T09:40:36.534507Z","iopub.status.idle":"2024-11-27T09:40:36.540354Z","shell.execute_reply.started":"2024-11-27T09:40:36.534472Z","shell.execute_reply":"2024-11-27T09:40:36.539362Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"def calculate_lengths(y, padding_value=0):\n    target_lengths = torch.sum(y != padding_value, dim=1) \n    return target_lengths\n\n\ndef train(dataloader, model, loss_fn, optimizer):\n    model.train()\n    train_loss = 0\n    for batch, (X, y) in enumerate(dataloader):\n        optimizer.zero_grad()\n        X, y = X.to(device), y.to(device) #y=b,3,length\n        y=y[:,1,:].squeeze(dim=1)         #b,t\n\n        # Forward pass\n        logits = model(X)  # Shape: (B, T, C)\n        logits = logits.permute(1, 0, 2)  # Shape: (T, B, C)\n\n        # Lengths\n        output_lengths = torch.full((X.size(0),), logits.size(0), dtype=torch.long, device=device)  # All T\n        target_lengths = calculate_lengths(y, padding_value=-1)\n\n        print(logits.shape,y.shape,X.shape)\n\n        # Loss calculation\n        # loss = loss_fn(logits.log_softmax(2), y, output_lengths, target_lengths)\n        train_loss += loss.item()\n\n        # Backward and optimization\n        loss.backward()\n        optimizer.step()\n\n        print(f\"Looked at {batch * len(X)/len(dataloader.dataset)*100} samples\", end='\\r')\n\n    train_loss /= len(dataloader)\n    return train_loss\n\n\n\ndef test(dataloader, model, loss_fn):\n    model.eval()  # Set the model to evaluation mode\n    test_loss, total_samples = 0, 0\n    correct = 0  # To accumulate correct predictions\n    blank_token = 0  # The blank token (you can change it if needed)\n\n    with torch.no_grad():  # Disable gradient computation\n        for batch, (X, y) in enumerate(dataloader):\n            X, y = X.to(device), y.to(device)\n            y = torch.tensor(y[:, 1, :].squeeze(dim=1)) #(b,t)\n            # Forward pass\n            logits = model(X)  # Shape: (B, T, C)\n            \n            logits = logits.permute(1, 0, 2)  # Shape: (T, B, C)\n\n            # Lengths\n            output_lengths = torch.full((X.size(0),), logits.size(0), dtype=torch.long, device=device)\n            target_lengths = calculate_lengths(y, padding_value=-1)\n\n            # Loss calculation\n            loss = loss_fn(logits.log_softmax(2), y, output_lengths, target_lengths)\n            test_loss += loss.item()\n\n            # Decode predictions (greedy decoding)\n            pred_labels = torch.argmax(logits, dim=-1)  # Shape: (T, B)\n            pred_labels = pred_labels.permute(1, 0)  # Shape: (B, T)\n\n            # Remove blanks and calculate accuracy\n            for c,seq in enumerate(pred_labels):\n                decoded = []\n                prev_token = None\n                for token in seq:\n                    token = token.item()\n                    if token != prev_token and token != blank_token:\n                        decoded.append(token)\n                decoded=[*decoded]+[-1]*(len(y[c])-len(decoded))\n                for i,letter in enumerate(y[c]):\n                    if letter==decoded[i]:\n                        correct+=1\n                    total_samples+=1\n\n            print(f\"Looked at {batch * len(X)/len(dataloader.dataset)*100} samples\", end='\\r')\n\n    test_loss /= len(dataloader)\n    accuracy = correct / (total_samples)  # Normalize by total number of elements\n\n    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2%}\")\n    return test_loss, accuracy\n\n\n        \ntrain(test_loader,model,loss_fn,optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:58:40.757724Z","iopub.execute_input":"2024-11-27T09:58:40.758677Z","iopub.status.idle":"2024-11-27T09:58:41.195083Z","shell.execute_reply.started":"2024-11-27T09:58:40.758631Z","shell.execute_reply":"2024-11-27T09:58:41.193626Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([32, 64, 100]) torch.Size([64, 28]) torch.Size([64, 1, 64, 256])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[88], line 92\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss, accuracy\n\u001b[0;32m---> 92\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[88], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape,y\u001b[38;5;241m.\u001b[39mshape,X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Loss calculation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# loss = loss_fn(logits.log_softmax(2), y, output_lengths, target_lengths)\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrequire_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Backward and optimization\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: tensor() got an unexpected keyword argument 'require_grad'"],"ename":"TypeError","evalue":"tensor() got an unexpected keyword argument 'require_grad'","output_type":"error"}],"execution_count":88},{"cell_type":"code","source":"# import torch\n\n# # Define tensors\n# x1 = torch.tensor([5], dtype=torch.float, requires_grad=True)\n# y1 = torch.tensor([1], dtype=torch.float, requires_grad=True)\n\n# x2 = torch.tensor([10], dtype=torch.float, requires_grad=True)\n# y2 = torch.tensor([2], dtype=torch.float, requires_grad=True)\n\n# # Perform operations\n# z1 = x1 + y1  # Scalar addition\n# z2 = x2 + y2  # Scalar addition\n\n# # Stack the results to form a tensor\n# z = torch.stack([z1, z2], dim=0)  # Shape: (2,)\n# y = z + torch.tensor([1.0, 1.0])  # Element-wise addition with a constant tensor\n\n# a=y.sum()\n# # Backpropagation\n# a.backward()  # Sum to create a scalar output for `backward`\n\n# # Print gradients\n# print(\"Gradient of x1:\", x1.grad)  # Gradient of x1\n# print(\"Gradient of x2:\", x2.grad)  # Gradient of x2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T12:26:08.576848Z","iopub.execute_input":"2024-11-26T12:26:08.577262Z","iopub.status.idle":"2024-11-26T12:26:08.587797Z","shell.execute_reply.started":"2024-11-26T12:26:08.577226Z","shell.execute_reply":"2024-11-26T12:26:08.586690Z"}},"outputs":[{"name":"stdout","text":"Gradient of x1: tensor([2.])\nGradient of x2: tensor([2.])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import torch\nparameters = {\n    \"train_losses\": [],\n    \"test_losses\": [],\n    \"test_accuracies\": [],\n    \"start_epoch\": 1,\n}\n\nepochs = 100\n\nload=False\nif load:\n    checkpoint = torch.load(\"checkpoint.pth\")\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n    parameters[\"start_epoch\"] = checkpoint[\"epoch\"] + 1\n    parameters[\"train_losses\"] = [*checkpoint[\"train_losses\"]]\n    parameters[\"test_losses\"] = [*checkpoint[\"test_losses\"]]\n    parameters[\"test_accuracies\"] = [*checkpoint[\"test_accuracies\"]]\n\n    \n\n\nfor epoch in range(parameters[\"start_epoch\"], epochs + 1):\n    print(f\"Epoch {epoch}/{epochs}\")\n\n\n    train_loss = train(train_loader, model, loss_fn, optimizer)\n    test_loss, accuracy = test(test_loader, model, loss_fn)\n\n\n    parameters[\"train_losses\"].append(train_loss)\n    parameters[\"test_losses\"].append(test_loss)\n    parameters[\"test_accuracies\"].append(accuracy)\n\n    print(f\"\\nTrain Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Accuracy: {accuracy:.2%}\")\n\n\n    checkpoint = {\n        \"epoch\": epoch,\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"train_losses\": parameters[\"train_losses\"],\n        \"test_losses\": parameters[\"test_losses\"],\n        \"test_accuracies\": parameters[\"test_accuracies\"],\n    }\n    torch.save(checkpoint, f\"/kaggle/working/checkpoint.pth\")\n    print(f\"Checkpoint saved for epoch {epoch}.\\n\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:40:42.753703Z","iopub.execute_input":"2024-11-27T09:40:42.754675Z","iopub.status.idle":"2024-11-27T09:44:37.916340Z","shell.execute_reply.started":"2024-11-27T09:40:42.754635Z","shell.execute_reply":"2024-11-27T09:44:37.914731Z"}},"outputs":[{"name":"stdout","text":"Epoch 9/100\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/2373931460.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(\"checkpoint.pth\")\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n","output_type":"stream"},{"name":"stdout","text":"Looked at 3.124963561525635 samplessss\r","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/704280370.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y = torch.tensor(y[:, 1, :].squeeze(dim=1)) #(b,t)\n","output_type":"stream"},{"name":"stdout","text":"Test Loss: nan, Test Accuracy: 76.19%\n\nTrain Loss: nan | Test Loss: nan | Accuracy: 76.19%\nCheckpoint saved for epoch 9.\n\nEpoch 10/100\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n/tmp/ipykernel_30/1825685539.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  label = torch.tensor(self.df_map.iloc[idx, 2:])\n","output_type":"stream"},{"name":"stdout","text":"Looked at 48.54421007217733 samplessss\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[78], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m], epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     test_loss, accuracy \u001b[38;5;241m=\u001b[39m test(test_loader, model, loss_fn)\n\u001b[1;32m     32\u001b[0m     parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n","Cell \u001b[0;32mIn[66], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m#y=b,3,length\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     y\u001b[38;5;241m=\u001b[39my[:,\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)         \u001b[38;5;66;03m#b,t\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n","File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":78},{"cell_type":"code","source":"with torch.no_grad():  # Disable gradient computation\n\n    X, y= next(iter(train_loader))\n    X, y = X.to(device), y.to(device)\n    y=y[:,1,:]\n    \n    logits = model(X)  # Shape: (B, T, C)\n\n    # Decode predictions (greedy decoding)\n    logits=logits.log_softmax(dim=2)\n    pred_labels = torch.argmax(logits, dim=2)\n    print(pred_labels)# Shape: (b,t)\n    \n    blank_idx=0\n    decoded_strings = []\n    exact_string=[]\n    for b in y:\n        exact_string.append(''.join([index_to_char[x.item()] for x in b if x!=0 and  x!=-1]))\n\n   \n\n    \n    for seq in pred_labels:\n        decoded = []\n        prev_token = None\n        for token in seq:\n            token = token.item()\n            if token != prev_token and token != blank_idx:\n                decoded.append(index_to_char[token])\n            prev_token = token\n        decoded_strings.append(''.join(decoded))\n    print(exact_string)\n    print(decoded_strings)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}